{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# path config\n",
    "#################\n",
    "ROOT_FOLDER = '/Users/keerat/Documents/Research'\n",
    "\n",
    "FILE_PATTERN = '*.jpg'\n",
    "\n",
    "OUTPUT_FILE_EXT = '.png'\n",
    "\n",
    "### Set to True if testset you are predicting stage2 folder\n",
    "is_stg2 = False\n",
    "\n",
    "### How much extra margin we want to include when cropping the output images\n",
    "margin = 0.15\n",
    "#margin = 0.4   #0.4 seems to work best for my classifier\n",
    "\n",
    "### Input folders\n",
    "TRAINSET_INPUT_FOLDER = ROOT_FOLDER + '/input/train'\n",
    "TESTSET_INPUT_FOLDER = ROOT_FOLDER + '/input/test_stg2' if is_stg2 else ROOT_FOLDER + '/input/test'\n",
    "ADDSET_INPUT_FOLDER = ROOT_FOLDER + '/input/additional'\n",
    "\n",
    "### Output folders\n",
    "TESTSET_OUTPUT_FOLDER = ROOT_FOLDER + '/input/test_stg2_roi_{}'.format(margin) if is_stg2 else ROOT_FOLDER + '/input/test_roi_{}'.format(margin)\n",
    "TRAINSET_OUTPUT_FOLDER = ROOT_FOLDER + '/input/train_roi_{}'.format(margin)\n",
    "ADDSET_OUTPUT_FOLDER = ROOT_FOLDER + '/input/additional_roi_{}'.format(margin)\n",
    "\n",
    "\n",
    "### Temp working folders\n",
    "TRAINSET_RESIZED_FOLDER = ROOT_FOLDER + '/input/train_resized'\n",
    "TESTSET_RESIZED_FOLDER = ROOT_FOLDER + '/input/test_stg2_resized' if is_stg2 else ROOT_FOLDER + '/input/test_resized'\n",
    "ADDSET_RESIZED_FOLDER = ROOT_FOLDER + '/input/additional_resized'\n",
    "VISUAL_RESIZED_FOLDER = ROOT_FOLDER + '/input/visual_resized'\n",
    "TRAINSET_RESIZED_MASK_FOLDER = ROOT_FOLDER + '/input/train_resized_mask'\n",
    "\n",
    "UNET_TRAIN_SPLIT_FOLDER = ROOT_FOLDER + '/input/split_unet/train_split/'\n",
    "UNET_TRAINMASK_SPLIT_FOLDER = ROOT_FOLDER + '/input/split_unet/train_mask_split/'\n",
    "\n",
    "UNET_VAL_SPLIT_FOLDER = ROOT_FOLDER + '/input/split_unet/val_split/'\n",
    "UNET_VALMASK_SPLIT_FOLDER = ROOT_FOLDER + '/input/split_unet/val_mask_split/'\n",
    "\n",
    "#################\n",
    "# other parameters\n",
    "#################\n",
    "ClassNames = ['Type_1', 'Type_2', 'Type_3']\n",
    "\n",
    "from sys import platform\n",
    "use_symlinks = platform == \"linux\" or platform == \"linux2\" or platform == \"darwin\"\n",
    "\n",
    "seed = 20170804\n",
    "split_proportion = 0.8\n",
    "\n",
    "learning_rate = 0.0001\n",
    "nbr_epochs = 400\n",
    "batch_size = 32\n",
    "\n",
    "# Size could be: 64, 80, 144, 128\n",
    "img_width = 128\n",
    "img_height = 128\n",
    "nb_channels = 3\n",
    "\n",
    "# Augmentation\n",
    "shear_range = 0.78\n",
    "zoom_range = 0.4\n",
    "rotation_range = 180\n",
    "vflip = True\n",
    "hflip = True\n",
    "width_shift_range = 0.3\n",
    "height_shift_range = 0.3\n",
    "\n",
    "# preprocessing\n",
    "rescale = 1. / 255.\n",
    "preprocessing_function = None\n",
    "\n",
    "# folder name\n",
    "info = 'unet' \\\n",
    "       + '_' + str(img_height) + 'x' + str(img_width) + 'x' + str(nb_channels) \\\n",
    "       + '_sp' + str(split_proportion) \\\n",
    "       + '_sh' + str(shear_range) \\\n",
    "       + '_zm' + str(zoom_range) \\\n",
    "       + '_rt' + str(rotation_range) \\\n",
    "       + '_vf' + str(int(vflip)) \\\n",
    "       + '_hf' + str(int(hflip)) \\\n",
    "       + '_ws' + str(width_shift_range) \\\n",
    "       + '_hs' + str(height_shift_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing train set & creating masks ...\n",
      "Loading /Users/keerat/Documents/Research/input/Type_1_bbox.json\n",
      "Processing 0/249\n",
      "Processing 10/249\n",
      "Processing 20/249\n",
      "Processing 30/249\n",
      "Processing 40/249\n",
      "Processing 50/249\n",
      "Processing 60/249\n",
      "Processing 70/249\n",
      "Processing 80/249\n",
      "Processing 90/249\n",
      "Processing 100/249\n",
      "Processing 110/249\n",
      "Processing 120/249\n",
      "Processing 130/249\n",
      "Processing 140/249\n",
      "Processing 150/249\n",
      "Processing 160/249\n",
      "Processing 170/249\n",
      "Processing 180/249\n",
      "Processing 190/249\n",
      "Processing 200/249\n",
      "Processing 210/249\n",
      "Processing 220/249\n",
      "Processing 230/249\n",
      "Processing 240/249\n",
      "Loading /Users/keerat/Documents/Research/input/Type_2_bbox.json\n",
      "Processing 0/772\n",
      "Processing 10/772\n",
      "Processing 20/772\n",
      "Processing 30/772\n",
      "Processing 40/772\n",
      "Processing 50/772\n",
      "Processing 60/772\n",
      "Processing 70/772\n",
      "Processing 80/772\n",
      "Processing 90/772\n",
      "Processing 100/772\n",
      "Processing 110/772\n",
      "Processing 120/772\n",
      "Processing 130/772\n",
      "Processing 140/772\n",
      "Processing 150/772\n",
      "Processing 160/772\n",
      "Processing 170/772\n",
      "Processing 180/772\n",
      "Processing 190/772\n",
      "Processing 200/772\n",
      "Processing 210/772\n",
      "Processing 220/772\n",
      "Processing 230/772\n",
      "Processing 240/772\n",
      "Processing 250/772\n",
      "Processing 260/772\n",
      "Processing 270/772\n",
      "Processing 280/772\n",
      "Processing 290/772\n",
      "Processing 300/772\n",
      "Processing 310/772\n",
      "Processing 320/772\n",
      "Processing 330/772\n",
      "Processing 340/772\n",
      "Processing 350/772\n",
      "Processing 360/772\n",
      "Processing 370/772\n",
      "Processing 380/772\n",
      "Processing 390/772\n",
      "Processing 400/772\n",
      "Processing 410/772\n",
      "Processing 420/772\n",
      "Processing 430/772\n",
      "Processing 440/772\n",
      "Processing 450/772\n",
      "Processing 460/772\n",
      "Processing 470/772\n",
      "Processing 480/772\n",
      "Processing 490/772\n",
      "Processing 500/772\n",
      "Processing 510/772\n",
      "Processing 520/772\n",
      "Processing 530/772\n",
      "Processing 540/772\n",
      "Processing 550/772\n",
      "Processing 560/772\n",
      "Processing 570/772\n",
      "Processing 580/772\n",
      "Processing 590/772\n",
      "Processing 600/772\n",
      "Processing 610/772\n",
      "Processing 620/772\n",
      "Processing 630/772\n",
      "Processing 640/772\n",
      "Processing 650/772\n",
      "Processing 660/772\n",
      "Processing 670/772\n",
      "Processing 680/772\n",
      "Processing 690/772\n",
      "Processing 700/772\n",
      "Processing 710/772\n",
      "Processing 720/772\n",
      "Processing 730/772\n",
      "Processing 740/772\n",
      "Processing 750/772\n",
      "Processing 760/772\n",
      "Processing 770/772\n",
      "Loading /Users/keerat/Documents/Research/input/Type_3_bbox.json\n",
      "Processing 0/445\n",
      "Processing 10/445\n",
      "Processing 20/445\n",
      "Processing 30/445\n",
      "Processing 40/445\n",
      "Processing 50/445\n",
      "Processing 60/445\n",
      "Processing 70/445\n",
      "Processing 80/445\n",
      "Processing 90/445\n",
      "Processing 100/445\n",
      "Processing 110/445\n",
      "Processing 120/445\n",
      "Processing 130/445\n",
      "Processing 140/445\n",
      "Processing 150/445\n",
      "Processing 160/445\n",
      "Processing 170/445\n",
      "Processing 180/445\n",
      "Processing 190/445\n",
      "Processing 200/445\n",
      "Processing 210/445\n",
      "Processing 220/445\n",
      "Processing 230/445\n",
      "Processing 240/445\n",
      "Processing 250/445\n",
      "Processing 260/445\n",
      "Processing 270/445\n",
      "Processing 280/445\n",
      "Processing 290/445\n",
      "Processing 300/445\n",
      "Processing 310/445\n",
      "Processing 320/445\n",
      "Processing 330/445\n",
      "Processing 340/445\n",
      "Processing 350/445\n",
      "Processing 360/445\n",
      "Processing 370/445\n",
      "Processing 380/445\n",
      "Processing 390/445\n",
      "Processing 400/445\n",
      "Processing 410/445\n",
      "Processing 420/445\n",
      "Processing 430/445\n",
      "Processing 440/445\n",
      "Resizing testset ...\n",
      "Resized 0/512 images\n",
      "Resized 100/512 images\n",
      "Resized 200/512 images\n",
      "Resized 300/512 images\n",
      "Resized 400/512 images\n",
      "Resized 500/512 images\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ntpath\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "\n",
    "def resize_testset(source_folder, target_folder, dsize, pattern=FILE_PATTERN):\n",
    "    print('Resizing testset ...')\n",
    "    if not os.path.exists(target_folder): os.makedirs(target_folder)\n",
    "    total_images = glob.glob(os.path.join(source_folder, pattern))\n",
    "    total = len(total_images)\n",
    "    for i, source in enumerate(total_images):\n",
    "        filename = ntpath.basename(source)\n",
    "        target = os.path.join(target_folder, filename.replace('.jpg', '.png'))\n",
    "\n",
    "        img = cv2.imread(source)\n",
    "        img_resized = cv2.resize(img, dsize, interpolation=cv2.INTER_CUBIC)\n",
    "        cv2.imwrite(target, img_resized)\n",
    "        if i % 100 == 0:\n",
    "            print(\"Resized {}/{} images\".format(i, total))\n",
    "\n",
    "\n",
    "def resize_addset(source_folder, target_folder, dsize, pattern=FILE_PATTERN):\n",
    "    print('Resizing additional set...')\n",
    "    if not os.path.exists(target_folder): os.makedirs(target_folder)\n",
    "    for clazz in ClassNames:\n",
    "        if clazz not in os.listdir(target_folder):\n",
    "            os.makedirs(os.path.join(target_folder, clazz))\n",
    "\n",
    "        total_images = glob.glob(os.path.join(source_folder, clazz, pattern))\n",
    "        total = len(total_images)\n",
    "        for i, source in enumerate(total_images):\n",
    "            filename = ntpath.basename(source)\n",
    "            target = os.path.join(target_folder, clazz, filename.replace('.jpg', '.png'))\n",
    "\n",
    "            try:\n",
    "                img = cv2.imread(source)\n",
    "                img_resized = cv2.resize(img, dsize, interpolation=cv2.INTER_CUBIC)\n",
    "                cv2.imwrite(target, img_resized)\n",
    "            except:\n",
    "                print('-------------------> error in: {}'.format(source))\n",
    "\n",
    "            if i % 20 == 0:\n",
    "                print(\"Resized {}/{} images\".format(i, total))\n",
    "\n",
    "\n",
    "def resize_trainset_and_generate_masks(dsize):\n",
    "    print('Resizing train set & creating masks ...')\n",
    "    INPUT_FOLDER = ROOT_FOLDER + '/input'\n",
    "    annotation_json_filename = INPUT_FOLDER + '/{}_bbox.json'\n",
    "    for c in ClassNames:\n",
    "\n",
    "        annotation_json = annotation_json_filename.format(c)\n",
    "        print('Loading {}'.format(annotation_json))\n",
    "        with open(annotation_json) as json_file:\n",
    "            data = json.load(json_file)\n",
    "\n",
    "        OUTPUT_FOLDER = os.path.join(TRAINSET_RESIZED_MASK_FOLDER, c)\n",
    "        if not os.path.exists(OUTPUT_FOLDER): os.makedirs(OUTPUT_FOLDER)\n",
    "\n",
    "        OUTPUT2_FOLDER = os.path.join(TRAINSET_RESIZED_FOLDER, c)\n",
    "        if not os.path.exists(OUTPUT2_FOLDER): os.makedirs(OUTPUT2_FOLDER)\n",
    "\n",
    "        total = len(data)\n",
    "        for i, row in enumerate(data):\n",
    "            if i % 10 == 0:\n",
    "                print('Processing {}/{}'.format(i, total))\n",
    "\n",
    "            input_filename = os.path.join(INPUT_FOLDER, row['filename'])\n",
    "            if not os.path.exists(input_filename):\n",
    "                print('Skipped input file not exist: {}'.format(input_filename))\n",
    "                continue\n",
    "\n",
    "            basename = ntpath.basename(input_filename)\n",
    "            output_filename = os.path.join(OUTPUT_FOLDER, basename.replace('.jpg', '.png'))\n",
    "            if os.path.exists(output_filename):\n",
    "                print('Skipped output already exist: {}'.format(output_filename))\n",
    "                continue\n",
    "\n",
    "            output2_filename = os.path.join(OUTPUT2_FOLDER, basename.replace('.jpg', '.png'))\n",
    "            if os.path.exists(output2_filename):\n",
    "                print('Skipped output already exist: {}'.format(output2_filename))\n",
    "                continue\n",
    "\n",
    "            annotation = row['annotations'][0]\n",
    "            x = int(round(annotation['x']))\n",
    "            y = int(round(annotation['y']))\n",
    "            w = int(round(annotation['width']))\n",
    "            h = int(round(annotation['height']))\n",
    "            img = cv2.imread(input_filename)\n",
    "\n",
    "            resized = cv2.resize(img, dsize=dsize)\n",
    "            cv2.imwrite(output2_filename, resized)\n",
    "\n",
    "            mask = np.zeros_like(img)\n",
    "            mask[y:y + h, x:x + w, :] = 255\n",
    "\n",
    "            mask = cv2.resize(mask, dsize=dsize)\n",
    "            cv2.imwrite(output_filename, mask)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    resize_trainset_and_generate_masks(dsize=(img_height, img_width))\n",
    "\n",
    "    resize_testset(TESTSET_INPUT_FOLDER, TESTSET_RESIZED_FOLDER, (img_width, img_height))\n",
    "\n",
    "    if os.path.exists(ADDSET_INPUT_FOLDER):\n",
    "        resize_addset(ADDSET_INPUT_FOLDER, ADDSET_RESIZED_FOLDER, (img_width, img_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
