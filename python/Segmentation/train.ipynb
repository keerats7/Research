{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# path config\n",
    "#################\n",
    "ROOT_FOLDER = '/Users/keerat/Documents/Research/'\n",
    "\n",
    "FILE_PATTERN = '*.jpg'\n",
    "\n",
    "OUTPUT_FILE_EXT = '.png'\n",
    "\n",
    "### Set to True if testset you are predicting stage2 folder\n",
    "is_stg2 = False\n",
    "\n",
    "### How much extra margin we want to include when cropping the output images\n",
    "margin = 0.15\n",
    "#margin = 0.4   #0.4 seems to work best for my classifier\n",
    "\n",
    "### Input folders\n",
    "TRAINSET_INPUT_FOLDER = ROOT_FOLDER + '/input/train'\n",
    "TESTSET_INPUT_FOLDER = ROOT_FOLDER + '/input/test_stg2' if is_stg2 else ROOT_FOLDER + '/input/test'\n",
    "ADDSET_INPUT_FOLDER = ROOT_FOLDER + '/input/additional'\n",
    "\n",
    "### Output folders\n",
    "TESTSET_OUTPUT_FOLDER = ROOT_FOLDER + '/input/test_stg2_roi_{}'.format(margin) if is_stg2 else ROOT_FOLDER + '/input/test_roi_{}'.format(margin)\n",
    "TRAINSET_OUTPUT_FOLDER = ROOT_FOLDER + '/input/train_roi_{}'.format(margin)\n",
    "ADDSET_OUTPUT_FOLDER = ROOT_FOLDER + '/input/additional_roi_{}'.format(margin)\n",
    "\n",
    "\n",
    "### Temp working folders\n",
    "TRAINSET_RESIZED_FOLDER = ROOT_FOLDER + '/input/train_resized'\n",
    "TESTSET_RESIZED_FOLDER = ROOT_FOLDER + '/input/test_stg2_resized' if is_stg2 else ROOT_FOLDER + '/input/test_resized'\n",
    "ADDSET_RESIZED_FOLDER = ROOT_FOLDER + '/input/additional_resized'\n",
    "VISUAL_RESIZED_FOLDER = ROOT_FOLDER + '/input/visual_resized'\n",
    "TRAINSET_RESIZED_MASK_FOLDER = ROOT_FOLDER + '/input/train_resized_mask'\n",
    "\n",
    "UNET_TRAIN_SPLIT_FOLDER = ROOT_FOLDER + '/input/split_unet/train_split/'\n",
    "UNET_TRAINMASK_SPLIT_FOLDER = ROOT_FOLDER + '/input/split_unet/train_mask_split/'\n",
    "\n",
    "UNET_VAL_SPLIT_FOLDER = ROOT_FOLDER + '/input/split_unet/val_split/'\n",
    "UNET_VALMASK_SPLIT_FOLDER = ROOT_FOLDER + '/input/split_unet/val_mask_split/'\n",
    "\n",
    "#################\n",
    "# other parameters\n",
    "#################\n",
    "ClassNames = ['Type_1', 'Type_2', 'Type_3']\n",
    "\n",
    "from sys import platform\n",
    "use_symlinks = platform == \"linux\" or platform == \"linux2\" or platform == \"darwin\"\n",
    "\n",
    "seed = 20170804\n",
    "split_proportion = 0.8\n",
    "\n",
    "learning_rate = 0.0001\n",
    "nbr_epochs = 400\n",
    "batch_size = 32\n",
    "\n",
    "# Size could be: 64, 80, 144, 128\n",
    "img_width = 128\n",
    "img_height = 128\n",
    "nb_channels = 3\n",
    "\n",
    "# Augmentation\n",
    "shear_range = 0.78\n",
    "zoom_range = 0.4\n",
    "rotation_range = 180\n",
    "vflip = True\n",
    "hflip = True\n",
    "width_shift_range = 0.3\n",
    "height_shift_range = 0.3\n",
    "\n",
    "# preprocessing\n",
    "rescale = 1. / 255.\n",
    "preprocessing_function = None\n",
    "\n",
    "# folder name\n",
    "info = 'unet' \\\n",
    "       + '_' + str(img_height) + 'x' + str(img_width) + 'x' + str(nb_channels) \\\n",
    "       + '_sp' + str(split_proportion) \\\n",
    "       + '_sh' + str(shear_range) \\\n",
    "       + '_zm' + str(zoom_range) \\\n",
    "       + '_rt' + str(rotation_range) \\\n",
    "       + '_vf' + str(int(vflip)) \\\n",
    "       + '_hf' + str(int(hflip)) \\\n",
    "       + '_ws' + str(width_shift_range) \\\n",
    "       + '_hs' + str(height_shift_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Input, MaxPooling2D, UpSampling2D, Conv2D\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "smooth = 1.\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def create_model(img_height, img_width, nb_channels, learning_rate):\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        channel_axis = 1\n",
    "        inputs = Input((nb_channels, img_height, img_width))\n",
    "    else:\n",
    "        channel_axis = 3\n",
    "        inputs = Input((img_height, img_width, nb_channels))\n",
    "    print('K.image_dim_ordering={} Channel axis={}'.format(K.image_dim_ordering(), channel_axis))\n",
    "\n",
    "    # inputs = Input((1, img_rows, img_cols))\n",
    "    conv1 = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\")(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\")(conv5)\n",
    "\n",
    "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=channel_axis)\n",
    "    conv6 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(conv6)\n",
    "\n",
    "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=channel_axis)\n",
    "    conv7 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(conv7)\n",
    "\n",
    "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=channel_axis)\n",
    "    conv8 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(conv8)\n",
    "\n",
    "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=channel_axis)\n",
    "    conv9 = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")(conv9)\n",
    "\n",
    "    conv10 = Conv2D(nb_channels, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_model(img_height, img_width, nb_channels, learning_rate, weight_file):\n",
    "    # Load model\n",
    "    print('Loading {} ...'.format(weight_file))\n",
    "    model = create_model(img_height, img_width, nb_channels, learning_rate)\n",
    "    model.load_weights(weight_file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def getCombinedImageDataGenerator(x_folder, y_folder, debug=False):\n",
    "    # we create two instances with the same arguments\n",
    "    data_gen_args = dict(\n",
    "        featurewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        rescale=rescale,\n",
    "        preprocessing_function=preprocessing_function,\n",
    "        shear_range=shear_range,\n",
    "        zoom_range=zoom_range,\n",
    "        rotation_range=rotation_range,\n",
    "        width_shift_range=width_shift_range,\n",
    "        height_shift_range=height_shift_range,\n",
    "        vertical_flip=vflip,\n",
    "        horizontal_flip=hflip)\n",
    "\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        x_folder,\n",
    "        class_mode=None,\n",
    "        seed=seed,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        save_to_dir=VISUAL_RESIZED_FOLDER if debug else None,\n",
    "        save_prefix='train' if debug else None,\n",
    "        follow_links=use_symlinks\n",
    "    )\n",
    "\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        y_folder,\n",
    "        class_mode=None,\n",
    "        seed=seed,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        save_to_dir=VISUAL_RESIZED_FOLDER if debug else None,\n",
    "        save_prefix='mask' if debug else None,\n",
    "        follow_links=use_symlinks\n",
    "    )\n",
    "\n",
    "    # combine generators into one which yields image and masks\n",
    "    try:\n",
    "        from itertools import izip\n",
    "    except ImportError:  #python3.x\n",
    "        izip = zip\n",
    "    combined_generator = izip(image_generator, mask_generator)\n",
    "    return combined_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2_morph_close(binary_image, size=5):\n",
    "    import cv2\n",
    "    from skimage.morphology import disk\n",
    "    kernel = disk(size)\n",
    "    result = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel)\n",
    "    return result\n",
    "\n",
    "\n",
    "def cv2_morph_open(binary_image, size=5):\n",
    "    import cv2\n",
    "    from skimage.morphology import disk\n",
    "    kernel = disk(size)\n",
    "    result = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel)\n",
    "    return result\n",
    "\n",
    "\n",
    "def morphology_clean(mask_binary):\n",
    "    return cv2_morph_close(cv2_morph_open(mask_binary))\n",
    "\n",
    "\n",
    "def getTimestamp():\n",
    "    import datetime\n",
    "    return datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "def save_training_history(info, history):\n",
    "    import matplotlib.pyplot as plt\n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.gcf().savefig('./' + info + '/loss_history.' + getTimestamp() + '.jpg')\n",
    "    # plt.show()\n",
    "\n",
    "    # summarize history for dice_coef\n",
    "    plt.plot(history.history['dice_coef'])\n",
    "    plt.plot(history.history['val_dice_coef'])\n",
    "    plt.title('model dice_coef')\n",
    "    plt.ylabel('dice_coef')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.gcf().savefig('./' + info + '/dice_coef_history.' + getTimestamp() + '.jpg')\n",
    "    # plt.show()\n",
    "\n",
    "    # history to json file\n",
    "    import json\n",
    "\n",
    "    with open('./' + info + '/log.' + getTimestamp() + '.json', 'w') as fp:\n",
    "        json.dump(history.history, fp, indent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Resume model and weights from previous training ...\n",
      "Loading unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5 ...\n",
      "K.image_dim_ordering=tf Channel axis=3\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 32) 9248        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 64)   18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 64)   36928       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 128)  73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 128)  147584      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 128)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 256)  295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 256)  590080      conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 256)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 512)    1180160     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 512)    2359808     conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 512)  0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 256)  1769728     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 256)  590080      conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 256)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 128)  442496      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 128)  0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 192)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 64)   110656      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 128, 128, 64) 0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128, 128, 96) 0           up_sampling2d_4[0][0]            \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 32) 27680       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 32) 9248        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 3)  99          conv2d_18[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,846,723\n",
      "Trainable params: 7,846,723\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "steps_per_epoch=37 , validation_steps=10 epochs=400\n",
      "Found 1172 images belonging to 3 classes.\n",
      "Found 1172 images belonging to 3 classes.\n",
      "Found 294 images belonging to 3 classes.\n",
      "Found 294 images belonging to 3 classes.\n",
      "Start training using ImageDataGenerator:\n",
      "Epoch 1/400\n",
      "37/37 [==============================] - 604s 16s/step - loss: -0.5092 - dice_coef: 0.5092 - val_loss: -0.2854 - val_dice_coef: 0.2854\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -0.28536, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 2/400\n",
      "37/37 [==============================] - 533s 14s/step - loss: -0.5912 - dice_coef: 0.5912 - val_loss: -0.5497 - val_dice_coef: 0.5497\n",
      "\n",
      "Epoch 00002: val_loss improved from -0.28536 to -0.54965, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/400\n",
      "37/37 [==============================] - 486s 13s/step - loss: -0.6094 - dice_coef: 0.6094 - val_loss: -0.5944 - val_dice_coef: 0.5944\n",
      "\n",
      "Epoch 00003: val_loss improved from -0.54965 to -0.59444, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 4/400\n",
      "37/37 [==============================] - 483s 13s/step - loss: -0.6082 - dice_coef: 0.6082 - val_loss: -0.6023 - val_dice_coef: 0.6023\n",
      "\n",
      "Epoch 00004: val_loss improved from -0.59444 to -0.60225, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 5/400\n",
      "37/37 [==============================] - 511s 14s/step - loss: -0.6086 - dice_coef: 0.6086 - val_loss: -0.6013 - val_dice_coef: 0.6013\n",
      "\n",
      "Epoch 00005: val_loss did not improve from -0.60225\n",
      "Epoch 6/400\n",
      "37/37 [==============================] - 572s 15s/step - loss: -0.6083 - dice_coef: 0.6083 - val_loss: -0.6118 - val_dice_coef: 0.6118\n",
      "\n",
      "Epoch 00006: val_loss improved from -0.60225 to -0.61180, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 7/400\n",
      "37/37 [==============================] - 517s 14s/step - loss: -0.6206 - dice_coef: 0.6206 - val_loss: -0.6214 - val_dice_coef: 0.6214\n",
      "\n",
      "Epoch 00007: val_loss improved from -0.61180 to -0.62137, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 8/400\n",
      "37/37 [==============================] - 515s 14s/step - loss: -0.6254 - dice_coef: 0.6254 - val_loss: -0.6234 - val_dice_coef: 0.6234\n",
      "\n",
      "Epoch 00008: val_loss improved from -0.62137 to -0.62342, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 9/400\n",
      "37/37 [==============================] - 567s 15s/step - loss: -0.6304 - dice_coef: 0.6304 - val_loss: -0.6160 - val_dice_coef: 0.6160\n",
      "\n",
      "Epoch 00009: val_loss did not improve from -0.62342\n",
      "Epoch 10/400\n",
      "37/37 [==============================] - 504s 14s/step - loss: -0.6367 - dice_coef: 0.6367 - val_loss: -0.6449 - val_dice_coef: 0.6449\n",
      "\n",
      "Epoch 00010: val_loss improved from -0.62342 to -0.64487, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 11/400\n",
      "37/37 [==============================] - 475s 13s/step - loss: -0.6329 - dice_coef: 0.6329 - val_loss: -0.6360 - val_dice_coef: 0.6360\n",
      "\n",
      "Epoch 00011: val_loss did not improve from -0.64487\n",
      "Epoch 12/400\n",
      "37/37 [==============================] - 472s 13s/step - loss: -0.6284 - dice_coef: 0.6284 - val_loss: -0.6415 - val_dice_coef: 0.6415\n",
      "\n",
      "Epoch 00012: val_loss did not improve from -0.64487\n",
      "Epoch 13/400\n",
      "37/37 [==============================] - 471s 13s/step - loss: -0.6325 - dice_coef: 0.6325 - val_loss: -0.6185 - val_dice_coef: 0.6185\n",
      "\n",
      "Epoch 00013: val_loss did not improve from -0.64487\n",
      "Epoch 14/400\n",
      "37/37 [==============================] - 469s 13s/step - loss: -0.6412 - dice_coef: 0.6412 - val_loss: -0.6493 - val_dice_coef: 0.6493\n",
      "\n",
      "Epoch 00014: val_loss improved from -0.64487 to -0.64932, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 15/400\n",
      "37/37 [==============================] - 474s 13s/step - loss: -0.6402 - dice_coef: 0.6402 - val_loss: -0.6184 - val_dice_coef: 0.6184\n",
      "\n",
      "Epoch 00015: val_loss did not improve from -0.64932\n",
      "Epoch 16/400\n",
      "37/37 [==============================] - 475s 13s/step - loss: -0.6397 - dice_coef: 0.6397 - val_loss: -0.6483 - val_dice_coef: 0.6483\n",
      "\n",
      "Epoch 00016: val_loss did not improve from -0.64932\n",
      "Epoch 17/400\n",
      "37/37 [==============================] - 471s 13s/step - loss: -0.6543 - dice_coef: 0.6543 - val_loss: -0.6385 - val_dice_coef: 0.6385\n",
      "\n",
      "Epoch 00017: val_loss did not improve from -0.64932\n",
      "Epoch 18/400\n",
      "37/37 [==============================] - 470s 13s/step - loss: -0.6490 - dice_coef: 0.6490 - val_loss: -0.6503 - val_dice_coef: 0.6503\n",
      "\n",
      "Epoch 00018: val_loss improved from -0.64932 to -0.65029, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 19/400\n",
      "37/37 [==============================] - 473s 13s/step - loss: -0.6625 - dice_coef: 0.6625 - val_loss: -0.6262 - val_dice_coef: 0.6262\n",
      "\n",
      "Epoch 00019: val_loss did not improve from -0.65029\n",
      "Epoch 20/400\n",
      "37/37 [==============================] - 470s 13s/step - loss: -0.6513 - dice_coef: 0.6513 - val_loss: -0.6328 - val_dice_coef: 0.6328\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -0.65029\n",
      "Epoch 21/400\n",
      "37/37 [==============================] - 471s 13s/step - loss: -0.6550 - dice_coef: 0.6550 - val_loss: -0.6406 - val_dice_coef: 0.6406\n",
      "\n",
      "Epoch 00021: val_loss did not improve from -0.65029\n",
      "Epoch 22/400\n",
      "37/37 [==============================] - 470s 13s/step - loss: -0.6532 - dice_coef: 0.6532 - val_loss: -0.6538 - val_dice_coef: 0.6538\n",
      "\n",
      "Epoch 00022: val_loss improved from -0.65029 to -0.65379, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 23/400\n",
      "37/37 [==============================] - 472s 13s/step - loss: -0.6623 - dice_coef: 0.6623 - val_loss: -0.6501 - val_dice_coef: 0.6501\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -0.65379\n",
      "Epoch 24/400\n",
      "37/37 [==============================] - 466s 13s/step - loss: -0.6614 - dice_coef: 0.6614 - val_loss: -0.6557 - val_dice_coef: 0.6557\n",
      "\n",
      "Epoch 00024: val_loss improved from -0.65379 to -0.65572, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 25/400\n",
      "37/37 [==============================] - 467s 13s/step - loss: -0.6645 - dice_coef: 0.6645 - val_loss: -0.6637 - val_dice_coef: 0.6637\n",
      "\n",
      "Epoch 00025: val_loss improved from -0.65572 to -0.66372, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 26/400\n",
      "37/37 [==============================] - 471s 13s/step - loss: -0.6748 - dice_coef: 0.6748 - val_loss: -0.6667 - val_dice_coef: 0.6667\n",
      "\n",
      "Epoch 00026: val_loss improved from -0.66372 to -0.66668, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 27/400\n",
      "37/37 [==============================] - 468s 13s/step - loss: -0.6734 - dice_coef: 0.6734 - val_loss: -0.6523 - val_dice_coef: 0.6523\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -0.66668\n",
      "Epoch 28/400\n",
      "37/37 [==============================] - 470s 13s/step - loss: -0.6562 - dice_coef: 0.6562 - val_loss: -0.6298 - val_dice_coef: 0.6298\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -0.66668\n",
      "Epoch 29/400\n",
      "37/37 [==============================] - 466s 13s/step - loss: -0.6616 - dice_coef: 0.6616 - val_loss: -0.6654 - val_dice_coef: 0.6654\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -0.66668\n",
      "Epoch 30/400\n",
      "37/37 [==============================] - 467s 13s/step - loss: -0.6736 - dice_coef: 0.6736 - val_loss: -0.6490 - val_dice_coef: 0.6490\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -0.66668\n",
      "Epoch 31/400\n",
      "37/37 [==============================] - 465s 13s/step - loss: -0.6686 - dice_coef: 0.6686 - val_loss: -0.6528 - val_dice_coef: 0.6528\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -0.66668\n",
      "Epoch 32/400\n",
      "37/37 [==============================] - 466s 13s/step - loss: -0.6759 - dice_coef: 0.6759 - val_loss: -0.6626 - val_dice_coef: 0.6626\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -0.66668\n",
      "Epoch 33/400\n",
      "37/37 [==============================] - 464s 13s/step - loss: -0.6676 - dice_coef: 0.6676 - val_loss: -0.6768 - val_dice_coef: 0.6768\n",
      "\n",
      "Epoch 00033: val_loss improved from -0.66668 to -0.67677, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 34/400\n",
      "37/37 [==============================] - 469s 13s/step - loss: -0.6765 - dice_coef: 0.6765 - val_loss: -0.6737 - val_dice_coef: 0.6737\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -0.67677\n",
      "Epoch 35/400\n",
      "37/37 [==============================] - 466s 13s/step - loss: -0.6806 - dice_coef: 0.6806 - val_loss: -0.6704 - val_dice_coef: 0.6704\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -0.67677\n",
      "Epoch 36/400\n",
      "37/37 [==============================] - 468s 13s/step - loss: -0.6820 - dice_coef: 0.6820 - val_loss: -0.6684 - val_dice_coef: 0.6684\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -0.67677\n",
      "Epoch 37/400\n",
      "37/37 [==============================] - 466s 13s/step - loss: -0.6914 - dice_coef: 0.6914 - val_loss: -0.6721 - val_dice_coef: 0.6721\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -0.67677\n",
      "Epoch 38/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 469s 13s/step - loss: -0.6857 - dice_coef: 0.6857 - val_loss: -0.6800 - val_dice_coef: 0.6800\n",
      "\n",
      "Epoch 00038: val_loss improved from -0.67677 to -0.67995, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 39/400\n",
      "37/37 [==============================] - 470s 13s/step - loss: -0.6787 - dice_coef: 0.6787 - val_loss: -0.6710 - val_dice_coef: 0.6710\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -0.67995\n",
      "Epoch 40/400\n",
      "37/37 [==============================] - 475s 13s/step - loss: -0.6869 - dice_coef: 0.6869 - val_loss: -0.6656 - val_dice_coef: 0.6656\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -0.67995\n",
      "Epoch 41/400\n",
      "37/37 [==============================] - 471s 13s/step - loss: -0.6834 - dice_coef: 0.6834 - val_loss: -0.6653 - val_dice_coef: 0.6653\n",
      "\n",
      "Epoch 00041: val_loss did not improve from -0.67995\n",
      "Epoch 42/400\n",
      "37/37 [==============================] - 537s 15s/step - loss: -0.6887 - dice_coef: 0.6887 - val_loss: -0.6671 - val_dice_coef: 0.6671\n",
      "\n",
      "Epoch 00042: val_loss did not improve from -0.67995\n",
      "Epoch 43/400\n",
      "37/37 [==============================] - 597s 16s/step - loss: -0.6890 - dice_coef: 0.6890 - val_loss: -0.6906 - val_dice_coef: 0.6906\n",
      "\n",
      "Epoch 00043: val_loss improved from -0.67995 to -0.69064, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 44/400\n",
      "37/37 [==============================] - 613s 17s/step - loss: -0.6905 - dice_coef: 0.6905 - val_loss: -0.6936 - val_dice_coef: 0.6936\n",
      "\n",
      "Epoch 00044: val_loss improved from -0.69064 to -0.69360, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 45/400\n",
      "37/37 [==============================] - 643s 17s/step - loss: -0.6997 - dice_coef: 0.6997 - val_loss: -0.6887 - val_dice_coef: 0.6887\n",
      "\n",
      "Epoch 00045: val_loss did not improve from -0.69360\n",
      "Epoch 46/400\n",
      "37/37 [==============================] - 637s 17s/step - loss: -0.6960 - dice_coef: 0.6960 - val_loss: -0.6845 - val_dice_coef: 0.6845\n",
      "\n",
      "Epoch 00046: val_loss did not improve from -0.69360\n",
      "Epoch 47/400\n",
      "37/37 [==============================] - 794s 21s/step - loss: -0.6914 - dice_coef: 0.6914 - val_loss: -0.6832 - val_dice_coef: 0.6832\n",
      "\n",
      "Epoch 00047: val_loss did not improve from -0.69360\n",
      "Epoch 48/400\n",
      "37/37 [==============================] - 663s 18s/step - loss: -0.6926 - dice_coef: 0.6926 - val_loss: -0.6916 - val_dice_coef: 0.6916\n",
      "\n",
      "Epoch 00048: val_loss did not improve from -0.69360\n",
      "Epoch 49/400\n",
      "37/37 [==============================] - 911s 25s/step - loss: -0.6899 - dice_coef: 0.6899 - val_loss: -0.6842 - val_dice_coef: 0.6842\n",
      "\n",
      "Epoch 00049: val_loss did not improve from -0.69360\n",
      "Epoch 50/400\n",
      "37/37 [==============================] - 665s 18s/step - loss: -0.7011 - dice_coef: 0.7011 - val_loss: -0.6984 - val_dice_coef: 0.6984\n",
      "\n",
      "Epoch 00050: val_loss improved from -0.69360 to -0.69836, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 51/400\n",
      "37/37 [==============================] - 469s 13s/step - loss: -0.6940 - dice_coef: 0.6940 - val_loss: -0.6894 - val_dice_coef: 0.6894\n",
      "\n",
      "Epoch 00051: val_loss did not improve from -0.69836\n",
      "Epoch 52/400\n",
      "37/37 [==============================] - 456s 12s/step - loss: -0.7031 - dice_coef: 0.7031 - val_loss: -0.6982 - val_dice_coef: 0.6982\n",
      "\n",
      "Epoch 00052: val_loss did not improve from -0.69836\n",
      "Epoch 53/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7043 - dice_coef: 0.7043 - val_loss: -0.7037 - val_dice_coef: 0.7037\n",
      "\n",
      "Epoch 00053: val_loss improved from -0.69836 to -0.70372, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 54/400\n",
      "37/37 [==============================] - 460s 12s/step - loss: -0.7006 - dice_coef: 0.7006 - val_loss: -0.7022 - val_dice_coef: 0.7022\n",
      "\n",
      "Epoch 00054: val_loss did not improve from -0.70372\n",
      "Epoch 55/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.6915 - dice_coef: 0.6915 - val_loss: -0.6909 - val_dice_coef: 0.6909\n",
      "\n",
      "Epoch 00055: val_loss did not improve from -0.70372\n",
      "Epoch 56/400\n",
      "37/37 [==============================] - 455s 12s/step - loss: -0.7049 - dice_coef: 0.7049 - val_loss: -0.6977 - val_dice_coef: 0.6977\n",
      "\n",
      "Epoch 00056: val_loss did not improve from -0.70372\n",
      "Epoch 57/400\n",
      "37/37 [==============================] - 453s 12s/step - loss: -0.6987 - dice_coef: 0.6987 - val_loss: -0.6830 - val_dice_coef: 0.6830\n",
      "\n",
      "Epoch 00057: val_loss did not improve from -0.70372\n",
      "Epoch 58/400\n",
      "37/37 [==============================] - 455s 12s/step - loss: -0.7034 - dice_coef: 0.7034 - val_loss: -0.6915 - val_dice_coef: 0.6915\n",
      "\n",
      "Epoch 00058: val_loss did not improve from -0.70372\n",
      "Epoch 59/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.6935 - dice_coef: 0.6935 - val_loss: -0.6600 - val_dice_coef: 0.6600\n",
      "\n",
      "Epoch 00059: val_loss did not improve from -0.70372\n",
      "Epoch 60/400\n",
      "37/37 [==============================] - 455s 12s/step - loss: -0.7006 - dice_coef: 0.7006 - val_loss: -0.6944 - val_dice_coef: 0.6944\n",
      "\n",
      "Epoch 00060: val_loss did not improve from -0.70372\n",
      "Epoch 61/400\n",
      "37/37 [==============================] - 454s 12s/step - loss: -0.7054 - dice_coef: 0.7054 - val_loss: -0.6809 - val_dice_coef: 0.6809\n",
      "\n",
      "Epoch 00061: val_loss did not improve from -0.70372\n",
      "Epoch 62/400\n",
      "37/37 [==============================] - 456s 12s/step - loss: -0.7096 - dice_coef: 0.7096 - val_loss: -0.6845 - val_dice_coef: 0.6845\n",
      "\n",
      "Epoch 00062: val_loss did not improve from -0.70372\n",
      "Epoch 63/400\n",
      "37/37 [==============================] - 460s 12s/step - loss: -0.7128 - dice_coef: 0.7128 - val_loss: -0.7182 - val_dice_coef: 0.7182\n",
      "\n",
      "Epoch 00063: val_loss improved from -0.70372 to -0.71823, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 64/400\n",
      "37/37 [==============================] - 465s 13s/step - loss: -0.7158 - dice_coef: 0.7158 - val_loss: -0.7094 - val_dice_coef: 0.7094\n",
      "\n",
      "Epoch 00064: val_loss did not improve from -0.71823\n",
      "Epoch 65/400\n",
      "37/37 [==============================] - 455s 12s/step - loss: -0.7071 - dice_coef: 0.7071 - val_loss: -0.6931 - val_dice_coef: 0.6931\n",
      "\n",
      "Epoch 00065: val_loss did not improve from -0.71823\n",
      "Epoch 66/400\n",
      "37/37 [==============================] - 455s 12s/step - loss: -0.7169 - dice_coef: 0.7169 - val_loss: -0.7071 - val_dice_coef: 0.7071\n",
      "\n",
      "Epoch 00066: val_loss did not improve from -0.71823\n",
      "Epoch 67/400\n",
      "37/37 [==============================] - 456s 12s/step - loss: -0.7118 - dice_coef: 0.7118 - val_loss: -0.6750 - val_dice_coef: 0.6750\n",
      "\n",
      "Epoch 00067: val_loss did not improve from -0.71823\n",
      "Epoch 68/400\n",
      "37/37 [==============================] - 456s 12s/step - loss: -0.7046 - dice_coef: 0.7046 - val_loss: -0.7023 - val_dice_coef: 0.7023\n",
      "\n",
      "Epoch 00068: val_loss did not improve from -0.71823\n",
      "Epoch 69/400\n",
      "37/37 [==============================] - 456s 12s/step - loss: -0.7200 - dice_coef: 0.7200 - val_loss: -0.7095 - val_dice_coef: 0.7095\n",
      "\n",
      "Epoch 00069: val_loss did not improve from -0.71823\n",
      "Epoch 70/400\n",
      "37/37 [==============================] - 458s 12s/step - loss: -0.7087 - dice_coef: 0.7087 - val_loss: -0.7072 - val_dice_coef: 0.7072\n",
      "\n",
      "Epoch 00070: val_loss did not improve from -0.71823\n",
      "Epoch 71/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7120 - dice_coef: 0.7120 - val_loss: -0.7109 - val_dice_coef: 0.7109\n",
      "\n",
      "Epoch 00071: val_loss did not improve from -0.71823\n",
      "Epoch 72/400\n",
      "37/37 [==============================] - 456s 12s/step - loss: -0.7134 - dice_coef: 0.7134 - val_loss: -0.7212 - val_dice_coef: 0.7212\n",
      "\n",
      "Epoch 00072: val_loss improved from -0.71823 to -0.72116, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 73/400\n",
      "37/37 [==============================] - 459s 12s/step - loss: -0.7119 - dice_coef: 0.7119 - val_loss: -0.7043 - val_dice_coef: 0.7043\n",
      "\n",
      "Epoch 00073: val_loss did not improve from -0.72116\n",
      "Epoch 74/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7207 - dice_coef: 0.7207 - val_loss: -0.6938 - val_dice_coef: 0.6938\n",
      "\n",
      "Epoch 00074: val_loss did not improve from -0.72116\n",
      "Epoch 75/400\n",
      "37/37 [==============================] - 460s 12s/step - loss: -0.7059 - dice_coef: 0.7059 - val_loss: -0.7077 - val_dice_coef: 0.7077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00075: val_loss did not improve from -0.72116\n",
      "Epoch 76/400\n",
      "37/37 [==============================] - 455s 12s/step - loss: -0.7181 - dice_coef: 0.7181 - val_loss: -0.7153 - val_dice_coef: 0.7153\n",
      "\n",
      "Epoch 00076: val_loss did not improve from -0.72116\n",
      "Epoch 77/400\n",
      "37/37 [==============================] - 456s 12s/step - loss: -0.7262 - dice_coef: 0.7262 - val_loss: -0.7177 - val_dice_coef: 0.7177\n",
      "\n",
      "Epoch 00077: val_loss did not improve from -0.72116\n",
      "Epoch 78/400\n",
      "37/37 [==============================] - 456s 12s/step - loss: -0.7271 - dice_coef: 0.7271 - val_loss: -0.7021 - val_dice_coef: 0.7021\n",
      "\n",
      "Epoch 00078: val_loss did not improve from -0.72116\n",
      "Epoch 79/400\n",
      "37/37 [==============================] - 458s 12s/step - loss: -0.7138 - dice_coef: 0.7138 - val_loss: -0.7114 - val_dice_coef: 0.7114\n",
      "\n",
      "Epoch 00079: val_loss did not improve from -0.72116\n",
      "Epoch 80/400\n",
      "37/37 [==============================] - 456s 12s/step - loss: -0.7175 - dice_coef: 0.7175 - val_loss: -0.7020 - val_dice_coef: 0.7020\n",
      "\n",
      "Epoch 00080: val_loss did not improve from -0.72116\n",
      "Epoch 81/400\n",
      "37/37 [==============================] - 456s 12s/step - loss: -0.7294 - dice_coef: 0.7294 - val_loss: -0.7261 - val_dice_coef: 0.7261\n",
      "\n",
      "Epoch 00081: val_loss improved from -0.72116 to -0.72611, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 82/400\n",
      "37/37 [==============================] - 458s 12s/step - loss: -0.7236 - dice_coef: 0.7236 - val_loss: -0.7244 - val_dice_coef: 0.7244\n",
      "\n",
      "Epoch 00082: val_loss did not improve from -0.72611\n",
      "Epoch 83/400\n",
      "37/37 [==============================] - 458s 12s/step - loss: -0.7206 - dice_coef: 0.7206 - val_loss: -0.7248 - val_dice_coef: 0.7248\n",
      "\n",
      "Epoch 00083: val_loss did not improve from -0.72611\n",
      "Epoch 84/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7298 - dice_coef: 0.7298 - val_loss: -0.7333 - val_dice_coef: 0.7333\n",
      "\n",
      "Epoch 00084: val_loss improved from -0.72611 to -0.73332, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 85/400\n",
      "37/37 [==============================] - 459s 12s/step - loss: -0.7316 - dice_coef: 0.7316 - val_loss: -0.7247 - val_dice_coef: 0.7247\n",
      "\n",
      "Epoch 00085: val_loss did not improve from -0.73332\n",
      "Epoch 86/400\n",
      "37/37 [==============================] - 455s 12s/step - loss: -0.7244 - dice_coef: 0.7244 - val_loss: -0.7151 - val_dice_coef: 0.7151\n",
      "\n",
      "Epoch 00086: val_loss did not improve from -0.73332\n",
      "Epoch 87/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7207 - dice_coef: 0.7207 - val_loss: -0.7202 - val_dice_coef: 0.7202\n",
      "\n",
      "Epoch 00087: val_loss did not improve from -0.73332\n",
      "Epoch 88/400\n",
      "37/37 [==============================] - 456s 12s/step - loss: -0.7259 - dice_coef: 0.7259 - val_loss: -0.7166 - val_dice_coef: 0.7166\n",
      "\n",
      "Epoch 00088: val_loss did not improve from -0.73332\n",
      "Epoch 89/400\n",
      "37/37 [==============================] - 461s 12s/step - loss: -0.7375 - dice_coef: 0.7375 - val_loss: -0.7266 - val_dice_coef: 0.7266\n",
      "\n",
      "Epoch 00089: val_loss did not improve from -0.73332\n",
      "Epoch 90/400\n",
      "37/37 [==============================] - 459s 12s/step - loss: -0.7271 - dice_coef: 0.7271 - val_loss: -0.7182 - val_dice_coef: 0.7182\n",
      "\n",
      "Epoch 00090: val_loss did not improve from -0.73332\n",
      "Epoch 91/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7326 - dice_coef: 0.7326 - val_loss: -0.7163 - val_dice_coef: 0.7163\n",
      "\n",
      "Epoch 00091: val_loss did not improve from -0.73332\n",
      "Epoch 92/400\n",
      "37/37 [==============================] - 455s 12s/step - loss: -0.7355 - dice_coef: 0.7355 - val_loss: -0.7289 - val_dice_coef: 0.7289\n",
      "\n",
      "Epoch 00092: val_loss did not improve from -0.73332\n",
      "Epoch 93/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7237 - dice_coef: 0.7237 - val_loss: -0.7017 - val_dice_coef: 0.7017\n",
      "\n",
      "Epoch 00093: val_loss did not improve from -0.73332\n",
      "Epoch 94/400\n",
      "37/37 [==============================] - 456s 12s/step - loss: -0.7327 - dice_coef: 0.7327 - val_loss: -0.7208 - val_dice_coef: 0.7208\n",
      "\n",
      "Epoch 00094: val_loss did not improve from -0.73332\n",
      "Epoch 95/400\n",
      "37/37 [==============================] - 459s 12s/step - loss: -0.7337 - dice_coef: 0.7337 - val_loss: -0.7234 - val_dice_coef: 0.7234\n",
      "\n",
      "Epoch 00095: val_loss did not improve from -0.73332\n",
      "Epoch 96/400\n",
      "37/37 [==============================] - 455s 12s/step - loss: -0.7342 - dice_coef: 0.7342 - val_loss: -0.7160 - val_dice_coef: 0.7160\n",
      "\n",
      "Epoch 00096: val_loss did not improve from -0.73332\n",
      "Epoch 97/400\n",
      "37/37 [==============================] - 456s 12s/step - loss: -0.7377 - dice_coef: 0.7377 - val_loss: -0.7215 - val_dice_coef: 0.7215\n",
      "\n",
      "Epoch 00097: val_loss did not improve from -0.73332\n",
      "Epoch 98/400\n",
      "37/37 [==============================] - 459s 12s/step - loss: -0.7427 - dice_coef: 0.7427 - val_loss: -0.7085 - val_dice_coef: 0.7085\n",
      "\n",
      "Epoch 00098: val_loss did not improve from -0.73332\n",
      "Epoch 99/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7296 - dice_coef: 0.7296 - val_loss: -0.7312 - val_dice_coef: 0.7312\n",
      "\n",
      "Epoch 00099: val_loss did not improve from -0.73332\n",
      "Epoch 100/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7333 - dice_coef: 0.7333 - val_loss: -0.7283 - val_dice_coef: 0.7283\n",
      "\n",
      "Epoch 00100: val_loss did not improve from -0.73332\n",
      "Epoch 101/400\n",
      "37/37 [==============================] - 456s 12s/step - loss: -0.7294 - dice_coef: 0.7294 - val_loss: -0.7105 - val_dice_coef: 0.7105\n",
      "\n",
      "Epoch 00101: val_loss did not improve from -0.73332\n",
      "Epoch 102/400\n",
      "37/37 [==============================] - 460s 12s/step - loss: -0.7369 - dice_coef: 0.7369 - val_loss: -0.7313 - val_dice_coef: 0.7313\n",
      "\n",
      "Epoch 00102: val_loss did not improve from -0.73332\n",
      "Epoch 103/400\n",
      "37/37 [==============================] - 459s 12s/step - loss: -0.7357 - dice_coef: 0.7357 - val_loss: -0.7147 - val_dice_coef: 0.7147\n",
      "\n",
      "Epoch 00103: val_loss did not improve from -0.73332\n",
      "Epoch 104/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7321 - dice_coef: 0.7321 - val_loss: -0.7369 - val_dice_coef: 0.7369\n",
      "\n",
      "Epoch 00104: val_loss improved from -0.73332 to -0.73690, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 105/400\n",
      "37/37 [==============================] - 459s 12s/step - loss: -0.7252 - dice_coef: 0.7252 - val_loss: -0.7250 - val_dice_coef: 0.7250\n",
      "\n",
      "Epoch 00105: val_loss did not improve from -0.73690\n",
      "Epoch 106/400\n",
      "37/37 [==============================] - 463s 13s/step - loss: -0.7401 - dice_coef: 0.7401 - val_loss: -0.7170 - val_dice_coef: 0.7170\n",
      "\n",
      "Epoch 00106: val_loss did not improve from -0.73690\n",
      "Epoch 107/400\n",
      "37/37 [==============================] - 460s 12s/step - loss: -0.7407 - dice_coef: 0.7407 - val_loss: -0.7209 - val_dice_coef: 0.7209\n",
      "\n",
      "Epoch 00107: val_loss did not improve from -0.73690\n",
      "Epoch 108/400\n",
      "37/37 [==============================] - 462s 12s/step - loss: -0.7450 - dice_coef: 0.7450 - val_loss: -0.7257 - val_dice_coef: 0.7257\n",
      "\n",
      "Epoch 00108: val_loss did not improve from -0.73690\n",
      "Epoch 109/400\n",
      "37/37 [==============================] - 460s 12s/step - loss: -0.7394 - dice_coef: 0.7394 - val_loss: -0.7039 - val_dice_coef: 0.7039\n",
      "\n",
      "Epoch 00109: val_loss did not improve from -0.73690\n",
      "Epoch 110/400\n",
      "37/37 [==============================] - 463s 13s/step - loss: -0.7342 - dice_coef: 0.7342 - val_loss: -0.7327 - val_dice_coef: 0.7327\n",
      "\n",
      "Epoch 00110: val_loss did not improve from -0.73690\n",
      "Epoch 111/400\n",
      "37/37 [==============================] - 462s 12s/step - loss: -0.7378 - dice_coef: 0.7378 - val_loss: -0.7277 - val_dice_coef: 0.7277\n",
      "\n",
      "Epoch 00111: val_loss did not improve from -0.73690\n",
      "Epoch 112/400\n",
      "37/37 [==============================] - 459s 12s/step - loss: -0.7380 - dice_coef: 0.7380 - val_loss: -0.7205 - val_dice_coef: 0.7205\n",
      "\n",
      "Epoch 00112: val_loss did not improve from -0.73690\n",
      "Epoch 113/400\n",
      "37/37 [==============================] - 459s 12s/step - loss: -0.7393 - dice_coef: 0.7393 - val_loss: -0.7222 - val_dice_coef: 0.7222\n",
      "\n",
      "Epoch 00113: val_loss did not improve from -0.73690\n",
      "Epoch 114/400\n",
      "37/37 [==============================] - 461s 12s/step - loss: -0.7418 - dice_coef: 0.7418 - val_loss: -0.7270 - val_dice_coef: 0.7270\n",
      "\n",
      "Epoch 00114: val_loss did not improve from -0.73690\n",
      "Epoch 115/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 461s 12s/step - loss: -0.7394 - dice_coef: 0.7394 - val_loss: -0.7376 - val_dice_coef: 0.7376\n",
      "\n",
      "Epoch 00115: val_loss improved from -0.73690 to -0.73759, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 116/400\n",
      "37/37 [==============================] - 465s 13s/step - loss: -0.7460 - dice_coef: 0.7460 - val_loss: -0.7268 - val_dice_coef: 0.7268\n",
      "\n",
      "Epoch 00116: val_loss did not improve from -0.73759\n",
      "Epoch 117/400\n",
      "37/37 [==============================] - 465s 13s/step - loss: -0.7434 - dice_coef: 0.7434 - val_loss: -0.7325 - val_dice_coef: 0.7325\n",
      "\n",
      "Epoch 00117: val_loss did not improve from -0.73759\n",
      "Epoch 118/400\n",
      "37/37 [==============================] - 465s 13s/step - loss: -0.7400 - dice_coef: 0.7400 - val_loss: -0.7212 - val_dice_coef: 0.7212\n",
      "\n",
      "Epoch 00118: val_loss did not improve from -0.73759\n",
      "Epoch 119/400\n",
      "37/37 [==============================] - 463s 13s/step - loss: -0.7450 - dice_coef: 0.7450 - val_loss: -0.7274 - val_dice_coef: 0.7274\n",
      "\n",
      "Epoch 00119: val_loss did not improve from -0.73759\n",
      "Epoch 120/400\n",
      "37/37 [==============================] - 464s 13s/step - loss: -0.7450 - dice_coef: 0.7450 - val_loss: -0.7437 - val_dice_coef: 0.7437\n",
      "\n",
      "Epoch 00120: val_loss improved from -0.73759 to -0.74373, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 121/400\n",
      "37/37 [==============================] - 466s 13s/step - loss: -0.7471 - dice_coef: 0.7471 - val_loss: -0.7326 - val_dice_coef: 0.7326\n",
      "\n",
      "Epoch 00121: val_loss did not improve from -0.74373\n",
      "Epoch 122/400\n",
      "37/37 [==============================] - 466s 13s/step - loss: -0.7439 - dice_coef: 0.7439 - val_loss: -0.7396 - val_dice_coef: 0.7396\n",
      "\n",
      "Epoch 00122: val_loss did not improve from -0.74373\n",
      "Epoch 123/400\n",
      "37/37 [==============================] - 466s 13s/step - loss: -0.7477 - dice_coef: 0.7477 - val_loss: -0.7398 - val_dice_coef: 0.7398\n",
      "\n",
      "Epoch 00123: val_loss did not improve from -0.74373\n",
      "Epoch 124/400\n",
      "37/37 [==============================] - 507s 14s/step - loss: -0.7559 - dice_coef: 0.7559 - val_loss: -0.7383 - val_dice_coef: 0.7383\n",
      "\n",
      "Epoch 00124: val_loss did not improve from -0.74373\n",
      "Epoch 125/400\n",
      "37/37 [==============================] - 540s 15s/step - loss: -0.7380 - dice_coef: 0.7380 - val_loss: -0.7179 - val_dice_coef: 0.7179\n",
      "\n",
      "Epoch 00125: val_loss did not improve from -0.74373\n",
      "Epoch 126/400\n",
      "37/37 [==============================] - 610s 16s/step - loss: -0.7370 - dice_coef: 0.7370 - val_loss: -0.7238 - val_dice_coef: 0.7238\n",
      "\n",
      "Epoch 00126: val_loss did not improve from -0.74373\n",
      "Epoch 127/400\n",
      "37/37 [==============================] - 603s 16s/step - loss: -0.7379 - dice_coef: 0.7379 - val_loss: -0.7258 - val_dice_coef: 0.7258\n",
      "\n",
      "Epoch 00127: val_loss did not improve from -0.74373\n",
      "Epoch 128/400\n",
      "37/37 [==============================] - 520s 14s/step - loss: -0.7448 - dice_coef: 0.7448 - val_loss: -0.7391 - val_dice_coef: 0.7391\n",
      "\n",
      "Epoch 00128: val_loss did not improve from -0.74373\n",
      "Epoch 129/400\n",
      "37/37 [==============================] - 573s 15s/step - loss: -0.7429 - dice_coef: 0.7429 - val_loss: -0.7195 - val_dice_coef: 0.7195\n",
      "\n",
      "Epoch 00129: val_loss did not improve from -0.74373\n",
      "Epoch 130/400\n",
      "37/37 [==============================] - 580s 16s/step - loss: -0.7501 - dice_coef: 0.7501 - val_loss: -0.7353 - val_dice_coef: 0.7353\n",
      "\n",
      "Epoch 00130: val_loss did not improve from -0.74373\n",
      "Epoch 131/400\n",
      "37/37 [==============================] - 600s 16s/step - loss: -0.7408 - dice_coef: 0.7408 - val_loss: -0.7223 - val_dice_coef: 0.7223\n",
      "\n",
      "Epoch 00131: val_loss did not improve from -0.74373\n",
      "Epoch 132/400\n",
      "37/37 [==============================] - 583s 16s/step - loss: -0.7486 - dice_coef: 0.7486 - val_loss: -0.7339 - val_dice_coef: 0.7339\n",
      "\n",
      "Epoch 00132: val_loss did not improve from -0.74373\n",
      "Epoch 133/400\n",
      "37/37 [==============================] - 531s 14s/step - loss: -0.7518 - dice_coef: 0.7518 - val_loss: -0.7384 - val_dice_coef: 0.7384\n",
      "\n",
      "Epoch 00133: val_loss did not improve from -0.74373\n",
      "Epoch 134/400\n",
      "37/37 [==============================] - 601s 16s/step - loss: -0.7557 - dice_coef: 0.7557 - val_loss: -0.7355 - val_dice_coef: 0.7355\n",
      "\n",
      "Epoch 00134: val_loss did not improve from -0.74373\n",
      "Epoch 135/400\n",
      "37/37 [==============================] - 687s 19s/step - loss: -0.7467 - dice_coef: 0.7467 - val_loss: -0.7310 - val_dice_coef: 0.7310\n",
      "\n",
      "Epoch 00135: val_loss did not improve from -0.74373\n",
      "Epoch 136/400\n",
      "37/37 [==============================] - 617s 17s/step - loss: -0.7513 - dice_coef: 0.7513 - val_loss: -0.7439 - val_dice_coef: 0.7439\n",
      "\n",
      "Epoch 00136: val_loss improved from -0.74373 to -0.74388, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 137/400\n",
      "37/37 [==============================] - 701s 19s/step - loss: -0.7552 - dice_coef: 0.7552 - val_loss: -0.7356 - val_dice_coef: 0.7356\n",
      "\n",
      "Epoch 00137: val_loss did not improve from -0.74388\n",
      "Epoch 138/400\n",
      "37/37 [==============================] - 604s 16s/step - loss: -0.7582 - dice_coef: 0.7582 - val_loss: -0.7525 - val_dice_coef: 0.7525\n",
      "\n",
      "Epoch 00138: val_loss improved from -0.74388 to -0.75253, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 139/400\n",
      "37/37 [==============================] - 615s 17s/step - loss: -0.7593 - dice_coef: 0.7593 - val_loss: -0.7483 - val_dice_coef: 0.7483\n",
      "\n",
      "Epoch 00139: val_loss did not improve from -0.75253\n",
      "Epoch 140/400\n",
      "37/37 [==============================] - 597s 16s/step - loss: -0.7535 - dice_coef: 0.7535 - val_loss: -0.7456 - val_dice_coef: 0.7456\n",
      "\n",
      "Epoch 00140: val_loss did not improve from -0.75253\n",
      "Epoch 141/400\n",
      "37/37 [==============================] - 663s 18s/step - loss: -0.7578 - dice_coef: 0.7578 - val_loss: -0.7446 - val_dice_coef: 0.7446\n",
      "\n",
      "Epoch 00141: val_loss did not improve from -0.75253\n",
      "Epoch 142/400\n",
      "37/37 [==============================] - 629s 17s/step - loss: -0.7640 - dice_coef: 0.7640 - val_loss: -0.7362 - val_dice_coef: 0.7362\n",
      "\n",
      "Epoch 00142: val_loss did not improve from -0.75253\n",
      "Epoch 143/400\n",
      "37/37 [==============================] - 500s 14s/step - loss: -0.7562 - dice_coef: 0.7562 - val_loss: -0.7397 - val_dice_coef: 0.7397\n",
      "\n",
      "Epoch 00143: val_loss did not improve from -0.75253\n",
      "Epoch 144/400\n",
      "37/37 [==============================] - 566s 15s/step - loss: -0.7506 - dice_coef: 0.7506 - val_loss: -0.7359 - val_dice_coef: 0.7359\n",
      "\n",
      "Epoch 00144: val_loss did not improve from -0.75253\n",
      "Epoch 145/400\n",
      "37/37 [==============================] - 579s 16s/step - loss: -0.7469 - dice_coef: 0.7469 - val_loss: -0.7440 - val_dice_coef: 0.7440\n",
      "\n",
      "Epoch 00145: val_loss did not improve from -0.75253\n",
      "Epoch 146/400\n",
      "37/37 [==============================] - 571s 15s/step - loss: -0.7537 - dice_coef: 0.7537 - val_loss: -0.7321 - val_dice_coef: 0.7321\n",
      "\n",
      "Epoch 00146: val_loss did not improve from -0.75253\n",
      "Epoch 147/400\n",
      "37/37 [==============================] - 511s 14s/step - loss: -0.7541 - dice_coef: 0.7541 - val_loss: -0.7352 - val_dice_coef: 0.7352\n",
      "\n",
      "Epoch 00147: val_loss did not improve from -0.75253\n",
      "Epoch 148/400\n",
      "37/37 [==============================] - 553s 15s/step - loss: -0.7589 - dice_coef: 0.7589 - val_loss: -0.7485 - val_dice_coef: 0.7485\n",
      "\n",
      "Epoch 00148: val_loss did not improve from -0.75253\n",
      "Epoch 149/400\n",
      "37/37 [==============================] - 652s 18s/step - loss: -0.7570 - dice_coef: 0.7570 - val_loss: -0.7500 - val_dice_coef: 0.7500\n",
      "\n",
      "Epoch 00149: val_loss did not improve from -0.75253\n",
      "Epoch 150/400\n",
      "37/37 [==============================] - 664s 18s/step - loss: -0.7556 - dice_coef: 0.7556 - val_loss: -0.7423 - val_dice_coef: 0.7423\n",
      "\n",
      "Epoch 00150: val_loss did not improve from -0.75253\n",
      "Epoch 151/400\n",
      "37/37 [==============================] - 615s 17s/step - loss: -0.7626 - dice_coef: 0.7626 - val_loss: -0.7401 - val_dice_coef: 0.7401\n",
      "\n",
      "Epoch 00151: val_loss did not improve from -0.75253\n",
      "Epoch 152/400\n",
      "37/37 [==============================] - 493s 13s/step - loss: -0.7542 - dice_coef: 0.7542 - val_loss: -0.7566 - val_dice_coef: 0.7566\n",
      "\n",
      "Epoch 00152: val_loss improved from -0.75253 to -0.75660, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 153/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 490s 13s/step - loss: -0.7611 - dice_coef: 0.7611 - val_loss: -0.7297 - val_dice_coef: 0.7297\n",
      "\n",
      "Epoch 00153: val_loss did not improve from -0.75660\n",
      "Epoch 154/400\n",
      "37/37 [==============================] - 562s 15s/step - loss: -0.7521 - dice_coef: 0.7521 - val_loss: -0.7515 - val_dice_coef: 0.7515\n",
      "\n",
      "Epoch 00154: val_loss did not improve from -0.75660\n",
      "Epoch 155/400\n",
      "37/37 [==============================] - 702s 19s/step - loss: -0.7489 - dice_coef: 0.7489 - val_loss: -0.7103 - val_dice_coef: 0.7103\n",
      "\n",
      "Epoch 00155: val_loss did not improve from -0.75660\n",
      "Epoch 156/400\n",
      "37/37 [==============================] - 624s 17s/step - loss: -0.7384 - dice_coef: 0.7384 - val_loss: -0.7229 - val_dice_coef: 0.7229\n",
      "\n",
      "Epoch 00156: val_loss did not improve from -0.75660\n",
      "Epoch 157/400\n",
      "37/37 [==============================] - 568s 15s/step - loss: -0.7633 - dice_coef: 0.7633 - val_loss: -0.7243 - val_dice_coef: 0.7243\n",
      "\n",
      "Epoch 00157: val_loss did not improve from -0.75660\n",
      "Epoch 158/400\n",
      "37/37 [==============================] - 543s 15s/step - loss: -0.7548 - dice_coef: 0.7548 - val_loss: -0.7287 - val_dice_coef: 0.7287\n",
      "\n",
      "Epoch 00158: val_loss did not improve from -0.75660\n",
      "Epoch 159/400\n",
      "37/37 [==============================] - 532s 14s/step - loss: -0.7528 - dice_coef: 0.7528 - val_loss: -0.7487 - val_dice_coef: 0.7487\n",
      "\n",
      "Epoch 00159: val_loss did not improve from -0.75660\n",
      "Epoch 160/400\n",
      "37/37 [==============================] - 552s 15s/step - loss: -0.7598 - dice_coef: 0.7598 - val_loss: -0.7480 - val_dice_coef: 0.7480\n",
      "\n",
      "Epoch 00160: val_loss did not improve from -0.75660\n",
      "Epoch 161/400\n",
      "37/37 [==============================] - 550s 15s/step - loss: -0.7546 - dice_coef: 0.7546 - val_loss: -0.7592 - val_dice_coef: 0.7592\n",
      "\n",
      "Epoch 00161: val_loss improved from -0.75660 to -0.75917, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 162/400\n",
      "37/37 [==============================] - 555s 15s/step - loss: -0.7581 - dice_coef: 0.7581 - val_loss: -0.7459 - val_dice_coef: 0.7459\n",
      "\n",
      "Epoch 00162: val_loss did not improve from -0.75917\n",
      "Epoch 163/400\n",
      "37/37 [==============================] - 573s 15s/step - loss: -0.7602 - dice_coef: 0.7602 - val_loss: -0.7442 - val_dice_coef: 0.7442\n",
      "\n",
      "Epoch 00163: val_loss did not improve from -0.75917\n",
      "Epoch 164/400\n",
      "37/37 [==============================] - 518s 14s/step - loss: -0.7553 - dice_coef: 0.7553 - val_loss: -0.7427 - val_dice_coef: 0.7427\n",
      "\n",
      "Epoch 00164: val_loss did not improve from -0.75917\n",
      "Epoch 165/400\n",
      "37/37 [==============================] - 549s 15s/step - loss: -0.7606 - dice_coef: 0.7606 - val_loss: -0.7477 - val_dice_coef: 0.7477\n",
      "\n",
      "Epoch 00165: val_loss did not improve from -0.75917\n",
      "Epoch 166/400\n",
      "37/37 [==============================] - 515s 14s/step - loss: -0.7476 - dice_coef: 0.7476 - val_loss: -0.7427 - val_dice_coef: 0.7427\n",
      "\n",
      "Epoch 00166: val_loss did not improve from -0.75917\n",
      "Epoch 167/400\n",
      "37/37 [==============================] - 536s 14s/step - loss: -0.7604 - dice_coef: 0.7604 - val_loss: -0.7464 - val_dice_coef: 0.7464\n",
      "\n",
      "Epoch 00167: val_loss did not improve from -0.75917\n",
      "Epoch 168/400\n",
      "37/37 [==============================] - 542s 15s/step - loss: -0.7598 - dice_coef: 0.7598 - val_loss: -0.7566 - val_dice_coef: 0.7566\n",
      "\n",
      "Epoch 00168: val_loss did not improve from -0.75917\n",
      "Epoch 169/400\n",
      "37/37 [==============================] - 680s 18s/step - loss: -0.7693 - dice_coef: 0.7693 - val_loss: -0.7454 - val_dice_coef: 0.7454\n",
      "\n",
      "Epoch 00169: val_loss did not improve from -0.75917\n",
      "Epoch 170/400\n",
      "37/37 [==============================] - 965s 26s/step - loss: -0.7649 - dice_coef: 0.7649 - val_loss: -0.7388 - val_dice_coef: 0.7388\n",
      "\n",
      "Epoch 00170: val_loss did not improve from -0.75917\n",
      "Epoch 171/400\n",
      "37/37 [==============================] - 1008s 27s/step - loss: -0.7665 - dice_coef: 0.7665 - val_loss: -0.7360 - val_dice_coef: 0.7360\n",
      "\n",
      "Epoch 00171: val_loss did not improve from -0.75917\n",
      "Epoch 172/400\n",
      "37/37 [==============================] - 693s 19s/step - loss: -0.7588 - dice_coef: 0.7588 - val_loss: -0.7377 - val_dice_coef: 0.7377\n",
      "\n",
      "Epoch 00172: val_loss did not improve from -0.75917\n",
      "Epoch 173/400\n",
      "37/37 [==============================] - 603s 16s/step - loss: -0.7489 - dice_coef: 0.7489 - val_loss: -0.7554 - val_dice_coef: 0.7554\n",
      "\n",
      "Epoch 00173: val_loss did not improve from -0.75917\n",
      "Epoch 174/400\n",
      "37/37 [==============================] - 482s 13s/step - loss: -0.7628 - dice_coef: 0.7628 - val_loss: -0.7404 - val_dice_coef: 0.7404\n",
      "\n",
      "Epoch 00174: val_loss did not improve from -0.75917\n",
      "Epoch 175/400\n",
      "37/37 [==============================] - 477s 13s/step - loss: -0.7634 - dice_coef: 0.7634 - val_loss: -0.7376 - val_dice_coef: 0.7376\n",
      "\n",
      "Epoch 00175: val_loss did not improve from -0.75917\n",
      "Epoch 176/400\n",
      "37/37 [==============================] - 473s 13s/step - loss: -0.7605 - dice_coef: 0.7605 - val_loss: -0.7509 - val_dice_coef: 0.7509\n",
      "\n",
      "Epoch 00176: val_loss did not improve from -0.75917\n",
      "Epoch 177/400\n",
      "37/37 [==============================] - 473s 13s/step - loss: -0.7656 - dice_coef: 0.7656 - val_loss: -0.7298 - val_dice_coef: 0.7298\n",
      "\n",
      "Epoch 00177: val_loss did not improve from -0.75917\n",
      "Epoch 178/400\n",
      "37/37 [==============================] - 474s 13s/step - loss: -0.7571 - dice_coef: 0.7571 - val_loss: -0.7578 - val_dice_coef: 0.7578\n",
      "\n",
      "Epoch 00178: val_loss did not improve from -0.75917\n",
      "Epoch 179/400\n",
      "37/37 [==============================] - 470s 13s/step - loss: -0.7640 - dice_coef: 0.7640 - val_loss: -0.7335 - val_dice_coef: 0.7335\n",
      "\n",
      "Epoch 00179: val_loss did not improve from -0.75917\n",
      "Epoch 180/400\n",
      "37/37 [==============================] - 468s 13s/step - loss: -0.7625 - dice_coef: 0.7625 - val_loss: -0.7495 - val_dice_coef: 0.7495\n",
      "\n",
      "Epoch 00180: val_loss did not improve from -0.75917\n",
      "Epoch 181/400\n",
      "37/37 [==============================] - 472s 13s/step - loss: -0.7651 - dice_coef: 0.7651 - val_loss: -0.7433 - val_dice_coef: 0.7433\n",
      "\n",
      "Epoch 00181: val_loss did not improve from -0.75917\n",
      "Epoch 182/400\n",
      "37/37 [==============================] - 469s 13s/step - loss: -0.7665 - dice_coef: 0.7665 - val_loss: -0.7425 - val_dice_coef: 0.7425\n",
      "\n",
      "Epoch 00182: val_loss did not improve from -0.75917\n",
      "Epoch 183/400\n",
      "37/37 [==============================] - 471s 13s/step - loss: -0.7613 - dice_coef: 0.7613 - val_loss: -0.7346 - val_dice_coef: 0.7346\n",
      "\n",
      "Epoch 00183: val_loss did not improve from -0.75917\n",
      "Epoch 184/400\n",
      "37/37 [==============================] - 467s 13s/step - loss: -0.7659 - dice_coef: 0.7659 - val_loss: -0.7626 - val_dice_coef: 0.7626\n",
      "\n",
      "Epoch 00184: val_loss improved from -0.75917 to -0.76256, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 185/400\n",
      "37/37 [==============================] - 476s 13s/step - loss: -0.7695 - dice_coef: 0.7695 - val_loss: -0.7489 - val_dice_coef: 0.7489\n",
      "\n",
      "Epoch 00185: val_loss did not improve from -0.76256\n",
      "Epoch 186/400\n",
      "37/37 [==============================] - 470s 13s/step - loss: -0.7689 - dice_coef: 0.7689 - val_loss: -0.7511 - val_dice_coef: 0.7511\n",
      "\n",
      "Epoch 00186: val_loss did not improve from -0.76256\n",
      "Epoch 187/400\n",
      "37/37 [==============================] - 471s 13s/step - loss: -0.7664 - dice_coef: 0.7664 - val_loss: -0.7494 - val_dice_coef: 0.7494\n",
      "\n",
      "Epoch 00187: val_loss did not improve from -0.76256\n",
      "Epoch 188/400\n",
      "37/37 [==============================] - 469s 13s/step - loss: -0.7727 - dice_coef: 0.7727 - val_loss: -0.7466 - val_dice_coef: 0.7466\n",
      "\n",
      "Epoch 00188: val_loss did not improve from -0.76256\n",
      "Epoch 189/400\n",
      "37/37 [==============================] - 476s 13s/step - loss: -0.7683 - dice_coef: 0.7683 - val_loss: -0.7449 - val_dice_coef: 0.7449\n",
      "\n",
      "Epoch 00189: val_loss did not improve from -0.76256\n",
      "Epoch 190/400\n",
      "37/37 [==============================] - 467s 13s/step - loss: -0.7720 - dice_coef: 0.7720 - val_loss: -0.7350 - val_dice_coef: 0.7350\n",
      "\n",
      "Epoch 00190: val_loss did not improve from -0.76256\n",
      "Epoch 191/400\n",
      "37/37 [==============================] - 485s 13s/step - loss: -0.7658 - dice_coef: 0.7658 - val_loss: -0.7368 - val_dice_coef: 0.7368\n",
      "\n",
      "Epoch 00191: val_loss did not improve from -0.76256\n",
      "Epoch 192/400\n",
      "37/37 [==============================] - 550s 15s/step - loss: -0.7623 - dice_coef: 0.7623 - val_loss: -0.7466 - val_dice_coef: 0.7466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00192: val_loss did not improve from -0.76256\n",
      "Epoch 193/400\n",
      "37/37 [==============================] - 669s 18s/step - loss: -0.6968 - dice_coef: 0.6968 - val_loss: -0.7209 - val_dice_coef: 0.7209\n",
      "\n",
      "Epoch 00193: val_loss did not improve from -0.76256\n",
      "Epoch 194/400\n",
      "37/37 [==============================] - 543s 15s/step - loss: -0.7437 - dice_coef: 0.7437 - val_loss: -0.7366 - val_dice_coef: 0.7366\n",
      "\n",
      "Epoch 00194: val_loss did not improve from -0.76256\n",
      "Epoch 195/400\n",
      "37/37 [==============================] - 529s 14s/step - loss: -0.7558 - dice_coef: 0.7558 - val_loss: -0.7465 - val_dice_coef: 0.7465\n",
      "\n",
      "Epoch 00195: val_loss did not improve from -0.76256\n",
      "Epoch 196/400\n",
      "37/37 [==============================] - 552s 15s/step - loss: -0.7617 - dice_coef: 0.7617 - val_loss: -0.7410 - val_dice_coef: 0.7410\n",
      "\n",
      "Epoch 00196: val_loss did not improve from -0.76256\n",
      "Epoch 197/400\n",
      "37/37 [==============================] - 593s 16s/step - loss: -0.7671 - dice_coef: 0.7671 - val_loss: -0.7635 - val_dice_coef: 0.7635\n",
      "\n",
      "Epoch 00197: val_loss improved from -0.76256 to -0.76355, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 198/400\n",
      "37/37 [==============================] - 595s 16s/step - loss: -0.7615 - dice_coef: 0.7615 - val_loss: -0.7634 - val_dice_coef: 0.7634\n",
      "\n",
      "Epoch 00198: val_loss did not improve from -0.76355\n",
      "Epoch 199/400\n",
      "37/37 [==============================] - 547s 15s/step - loss: -0.7613 - dice_coef: 0.7613 - val_loss: -0.7536 - val_dice_coef: 0.7536\n",
      "\n",
      "Epoch 00199: val_loss did not improve from -0.76355\n",
      "Epoch 200/400\n",
      "37/37 [==============================] - 574s 16s/step - loss: -0.7696 - dice_coef: 0.7696 - val_loss: -0.7447 - val_dice_coef: 0.7447\n",
      "\n",
      "Epoch 00200: val_loss did not improve from -0.76355\n",
      "Epoch 201/400\n",
      "37/37 [==============================] - 551s 15s/step - loss: -0.7629 - dice_coef: 0.7629 - val_loss: -0.7351 - val_dice_coef: 0.7351\n",
      "\n",
      "Epoch 00201: val_loss did not improve from -0.76355\n",
      "Epoch 202/400\n",
      "37/37 [==============================] - 560s 15s/step - loss: -0.7669 - dice_coef: 0.7669 - val_loss: -0.7397 - val_dice_coef: 0.7397\n",
      "\n",
      "Epoch 00202: val_loss did not improve from -0.76355\n",
      "Epoch 203/400\n",
      "37/37 [==============================] - 571s 15s/step - loss: -0.7657 - dice_coef: 0.7657 - val_loss: -0.7558 - val_dice_coef: 0.7558\n",
      "\n",
      "Epoch 00203: val_loss did not improve from -0.76355\n",
      "Epoch 204/400\n",
      "37/37 [==============================] - 525s 14s/step - loss: -0.7710 - dice_coef: 0.7710 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
      "\n",
      "Epoch 00204: val_loss did not improve from -0.76355\n",
      "Epoch 205/400\n",
      "37/37 [==============================] - 465s 13s/step - loss: -0.7690 - dice_coef: 0.7690 - val_loss: -0.7536 - val_dice_coef: 0.7536\n",
      "\n",
      "Epoch 00205: val_loss did not improve from -0.76355\n",
      "Epoch 206/400\n",
      "37/37 [==============================] - 463s 13s/step - loss: -0.7703 - dice_coef: 0.7703 - val_loss: -0.7451 - val_dice_coef: 0.7451\n",
      "\n",
      "Epoch 00206: val_loss did not improve from -0.76355\n",
      "Epoch 207/400\n",
      "37/37 [==============================] - 460s 12s/step - loss: -0.7719 - dice_coef: 0.7719 - val_loss: -0.7616 - val_dice_coef: 0.7616\n",
      "\n",
      "Epoch 00207: val_loss did not improve from -0.76355\n",
      "Epoch 208/400\n",
      "37/37 [==============================] - 468s 13s/step - loss: -0.7735 - dice_coef: 0.7735 - val_loss: -0.7582 - val_dice_coef: 0.7582\n",
      "\n",
      "Epoch 00208: val_loss did not improve from -0.76355\n",
      "Epoch 209/400\n",
      "37/37 [==============================] - 462s 12s/step - loss: -0.7732 - dice_coef: 0.7732 - val_loss: -0.7610 - val_dice_coef: 0.7610\n",
      "\n",
      "Epoch 00209: val_loss did not improve from -0.76355\n",
      "Epoch 210/400\n",
      "37/37 [==============================] - 463s 13s/step - loss: -0.7776 - dice_coef: 0.7776 - val_loss: -0.7343 - val_dice_coef: 0.7343\n",
      "\n",
      "Epoch 00210: val_loss did not improve from -0.76355\n",
      "Epoch 211/400\n",
      "37/37 [==============================] - 464s 13s/step - loss: -0.7695 - dice_coef: 0.7695 - val_loss: -0.7465 - val_dice_coef: 0.7465\n",
      "\n",
      "Epoch 00211: val_loss did not improve from -0.76355\n",
      "Epoch 212/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7667 - dice_coef: 0.7667 - val_loss: -0.7652 - val_dice_coef: 0.7652\n",
      "\n",
      "Epoch 00212: val_loss improved from -0.76355 to -0.76520, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 213/400\n",
      "37/37 [==============================] - 466s 13s/step - loss: -0.7733 - dice_coef: 0.7733 - val_loss: -0.7561 - val_dice_coef: 0.7561\n",
      "\n",
      "Epoch 00213: val_loss did not improve from -0.76520\n",
      "Epoch 214/400\n",
      "37/37 [==============================] - 458s 12s/step - loss: -0.7677 - dice_coef: 0.7677 - val_loss: -0.7561 - val_dice_coef: 0.7561\n",
      "\n",
      "Epoch 00214: val_loss did not improve from -0.76520\n",
      "Epoch 215/400\n",
      "37/37 [==============================] - 460s 12s/step - loss: -0.7755 - dice_coef: 0.7755 - val_loss: -0.7536 - val_dice_coef: 0.7536\n",
      "\n",
      "Epoch 00215: val_loss did not improve from -0.76520\n",
      "Epoch 216/400\n",
      "37/37 [==============================] - 459s 12s/step - loss: -0.7727 - dice_coef: 0.7727 - val_loss: -0.7443 - val_dice_coef: 0.7443\n",
      "\n",
      "Epoch 00216: val_loss did not improve from -0.76520\n",
      "Epoch 217/400\n",
      "37/37 [==============================] - 462s 12s/step - loss: -0.7758 - dice_coef: 0.7758 - val_loss: -0.7529 - val_dice_coef: 0.7529\n",
      "\n",
      "Epoch 00217: val_loss did not improve from -0.76520\n",
      "Epoch 218/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7690 - dice_coef: 0.7690 - val_loss: -0.7516 - val_dice_coef: 0.7516\n",
      "\n",
      "Epoch 00218: val_loss did not improve from -0.76520\n",
      "Epoch 219/400\n",
      "37/37 [==============================] - 458s 12s/step - loss: -0.7721 - dice_coef: 0.7721 - val_loss: -0.7467 - val_dice_coef: 0.7467\n",
      "\n",
      "Epoch 00219: val_loss did not improve from -0.76520\n",
      "Epoch 220/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7692 - dice_coef: 0.7692 - val_loss: -0.7524 - val_dice_coef: 0.7524\n",
      "\n",
      "Epoch 00220: val_loss did not improve from -0.76520\n",
      "Epoch 221/400\n",
      "37/37 [==============================] - 460s 12s/step - loss: -0.7654 - dice_coef: 0.7654 - val_loss: -0.7424 - val_dice_coef: 0.7424\n",
      "\n",
      "Epoch 00221: val_loss did not improve from -0.76520\n",
      "Epoch 222/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7676 - dice_coef: 0.7676 - val_loss: -0.7522 - val_dice_coef: 0.7522\n",
      "\n",
      "Epoch 00222: val_loss did not improve from -0.76520\n",
      "Epoch 223/400\n",
      "37/37 [==============================] - 461s 12s/step - loss: -0.7687 - dice_coef: 0.7687 - val_loss: -0.7585 - val_dice_coef: 0.7585\n",
      "\n",
      "Epoch 00223: val_loss did not improve from -0.76520\n",
      "Epoch 224/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7684 - dice_coef: 0.7684 - val_loss: -0.7538 - val_dice_coef: 0.7538\n",
      "\n",
      "Epoch 00224: val_loss did not improve from -0.76520\n",
      "Epoch 225/400\n",
      "37/37 [==============================] - 461s 12s/step - loss: -0.7730 - dice_coef: 0.7730 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
      "\n",
      "Epoch 00225: val_loss did not improve from -0.76520\n",
      "Epoch 226/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7657 - dice_coef: 0.7657 - val_loss: -0.7484 - val_dice_coef: 0.7484\n",
      "\n",
      "Epoch 00226: val_loss did not improve from -0.76520\n",
      "Epoch 227/400\n",
      "37/37 [==============================] - 458s 12s/step - loss: -0.7727 - dice_coef: 0.7727 - val_loss: -0.7609 - val_dice_coef: 0.7609\n",
      "\n",
      "Epoch 00227: val_loss did not improve from -0.76520\n",
      "Epoch 228/400\n",
      "37/37 [==============================] - 458s 12s/step - loss: -0.7737 - dice_coef: 0.7737 - val_loss: -0.7567 - val_dice_coef: 0.7567\n",
      "\n",
      "Epoch 00228: val_loss did not improve from -0.76520\n",
      "Epoch 229/400\n",
      "37/37 [==============================] - 459s 12s/step - loss: -0.7745 - dice_coef: 0.7745 - val_loss: -0.7631 - val_dice_coef: 0.7631\n",
      "\n",
      "Epoch 00229: val_loss did not improve from -0.76520\n",
      "Epoch 230/400\n",
      "37/37 [==============================] - 464s 13s/step - loss: -0.7727 - dice_coef: 0.7727 - val_loss: -0.7566 - val_dice_coef: 0.7566\n",
      "\n",
      "Epoch 00230: val_loss did not improve from -0.76520\n",
      "Epoch 231/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7720 - dice_coef: 0.7720 - val_loss: -0.7581 - val_dice_coef: 0.7581\n",
      "\n",
      "Epoch 00231: val_loss did not improve from -0.76520\n",
      "Epoch 232/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 458s 12s/step - loss: -0.7698 - dice_coef: 0.7698 - val_loss: -0.7519 - val_dice_coef: 0.7519\n",
      "\n",
      "Epoch 00232: val_loss did not improve from -0.76520\n",
      "Epoch 233/400\n",
      "37/37 [==============================] - 463s 13s/step - loss: -0.7652 - dice_coef: 0.7652 - val_loss: -0.7510 - val_dice_coef: 0.7510\n",
      "\n",
      "Epoch 00233: val_loss did not improve from -0.76520\n",
      "Epoch 234/400\n",
      "37/37 [==============================] - 458s 12s/step - loss: -0.7808 - dice_coef: 0.7808 - val_loss: -0.7584 - val_dice_coef: 0.7584\n",
      "\n",
      "Epoch 00234: val_loss did not improve from -0.76520\n",
      "Epoch 235/400\n",
      "37/37 [==============================] - 456s 12s/step - loss: -0.7756 - dice_coef: 0.7756 - val_loss: -0.7490 - val_dice_coef: 0.7490\n",
      "\n",
      "Epoch 00235: val_loss did not improve from -0.76520\n",
      "Epoch 236/400\n",
      "37/37 [==============================] - 460s 12s/step - loss: -0.7767 - dice_coef: 0.7767 - val_loss: -0.7670 - val_dice_coef: 0.7670\n",
      "\n",
      "Epoch 00236: val_loss improved from -0.76520 to -0.76695, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 237/400\n",
      "37/37 [==============================] - 462s 12s/step - loss: -0.7772 - dice_coef: 0.7772 - val_loss: -0.7628 - val_dice_coef: 0.7628\n",
      "\n",
      "Epoch 00237: val_loss did not improve from -0.76695\n",
      "Epoch 238/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7679 - dice_coef: 0.7679 - val_loss: -0.7602 - val_dice_coef: 0.7602\n",
      "\n",
      "Epoch 00238: val_loss did not improve from -0.76695\n",
      "Epoch 239/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7730 - dice_coef: 0.7730 - val_loss: -0.7586 - val_dice_coef: 0.7586\n",
      "\n",
      "Epoch 00239: val_loss did not improve from -0.76695\n",
      "Epoch 240/400\n",
      "37/37 [==============================] - 462s 12s/step - loss: -0.7759 - dice_coef: 0.7759 - val_loss: -0.7657 - val_dice_coef: 0.7657\n",
      "\n",
      "Epoch 00240: val_loss did not improve from -0.76695\n",
      "Epoch 241/400\n",
      "37/37 [==============================] - 458s 12s/step - loss: -0.7763 - dice_coef: 0.7763 - val_loss: -0.7656 - val_dice_coef: 0.7656\n",
      "\n",
      "Epoch 00241: val_loss did not improve from -0.76695\n",
      "Epoch 242/400\n",
      "37/37 [==============================] - 459s 12s/step - loss: -0.7742 - dice_coef: 0.7742 - val_loss: -0.7609 - val_dice_coef: 0.7609\n",
      "\n",
      "Epoch 00242: val_loss did not improve from -0.76695\n",
      "Epoch 243/400\n",
      "37/37 [==============================] - 458s 12s/step - loss: -0.7751 - dice_coef: 0.7751 - val_loss: -0.7548 - val_dice_coef: 0.7548\n",
      "\n",
      "Epoch 00243: val_loss did not improve from -0.76695\n",
      "Epoch 244/400\n",
      "37/37 [==============================] - 460s 12s/step - loss: -0.7751 - dice_coef: 0.7751 - val_loss: -0.7535 - val_dice_coef: 0.7535\n",
      "\n",
      "Epoch 00244: val_loss did not improve from -0.76695\n",
      "Epoch 245/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7783 - dice_coef: 0.7783 - val_loss: -0.7685 - val_dice_coef: 0.7685\n",
      "\n",
      "Epoch 00245: val_loss improved from -0.76695 to -0.76849, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 246/400\n",
      "37/37 [==============================] - 461s 12s/step - loss: -0.7708 - dice_coef: 0.7708 - val_loss: -0.7400 - val_dice_coef: 0.7400\n",
      "\n",
      "Epoch 00246: val_loss did not improve from -0.76849\n",
      "Epoch 247/400\n",
      "37/37 [==============================] - 458s 12s/step - loss: -0.7783 - dice_coef: 0.7783 - val_loss: -0.7509 - val_dice_coef: 0.7509\n",
      "\n",
      "Epoch 00247: val_loss did not improve from -0.76849\n",
      "Epoch 248/400\n",
      "37/37 [==============================] - 461s 12s/step - loss: -0.7731 - dice_coef: 0.7731 - val_loss: -0.7523 - val_dice_coef: 0.7523\n",
      "\n",
      "Epoch 00248: val_loss did not improve from -0.76849\n",
      "Epoch 249/400\n",
      "37/37 [==============================] - 458s 12s/step - loss: -0.7773 - dice_coef: 0.7773 - val_loss: -0.7597 - val_dice_coef: 0.7597\n",
      "\n",
      "Epoch 00249: val_loss did not improve from -0.76849\n",
      "Epoch 250/400\n",
      "37/37 [==============================] - 458s 12s/step - loss: -0.7733 - dice_coef: 0.7733 - val_loss: -0.7650 - val_dice_coef: 0.7650\n",
      "\n",
      "Epoch 00250: val_loss did not improve from -0.76849\n",
      "Epoch 251/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7699 - dice_coef: 0.7699 - val_loss: -0.7576 - val_dice_coef: 0.7576\n",
      "\n",
      "Epoch 00251: val_loss did not improve from -0.76849\n",
      "Epoch 252/400\n",
      "37/37 [==============================] - 458s 12s/step - loss: -0.7825 - dice_coef: 0.7825 - val_loss: -0.7540 - val_dice_coef: 0.7540\n",
      "\n",
      "Epoch 00252: val_loss did not improve from -0.76849\n",
      "Epoch 253/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7756 - dice_coef: 0.7756 - val_loss: -0.7431 - val_dice_coef: 0.7431\n",
      "\n",
      "Epoch 00253: val_loss did not improve from -0.76849\n",
      "Epoch 254/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7797 - dice_coef: 0.7797 - val_loss: -0.7529 - val_dice_coef: 0.7529\n",
      "\n",
      "Epoch 00254: val_loss did not improve from -0.76849\n",
      "Epoch 255/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7755 - dice_coef: 0.7755 - val_loss: -0.7592 - val_dice_coef: 0.7592\n",
      "\n",
      "Epoch 00255: val_loss did not improve from -0.76849\n",
      "Epoch 256/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7739 - dice_coef: 0.7739 - val_loss: -0.7664 - val_dice_coef: 0.7664\n",
      "\n",
      "Epoch 00256: val_loss did not improve from -0.76849\n",
      "Epoch 257/400\n",
      "37/37 [==============================] - 458s 12s/step - loss: -0.7731 - dice_coef: 0.7731 - val_loss: -0.7575 - val_dice_coef: 0.7575\n",
      "\n",
      "Epoch 00257: val_loss did not improve from -0.76849\n",
      "Epoch 258/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7707 - dice_coef: 0.7707 - val_loss: -0.7473 - val_dice_coef: 0.7473\n",
      "\n",
      "Epoch 00258: val_loss did not improve from -0.76849\n",
      "Epoch 259/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7701 - dice_coef: 0.7701 - val_loss: -0.7571 - val_dice_coef: 0.7571\n",
      "\n",
      "Epoch 00259: val_loss did not improve from -0.76849\n",
      "Epoch 260/400\n",
      "37/37 [==============================] - 460s 12s/step - loss: -0.7792 - dice_coef: 0.7792 - val_loss: -0.7687 - val_dice_coef: 0.7687\n",
      "\n",
      "Epoch 00260: val_loss improved from -0.76849 to -0.76870, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 261/400\n",
      "37/37 [==============================] - 461s 12s/step - loss: -0.7803 - dice_coef: 0.7803 - val_loss: -0.7511 - val_dice_coef: 0.7511\n",
      "\n",
      "Epoch 00261: val_loss did not improve from -0.76870\n",
      "Epoch 262/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7732 - dice_coef: 0.7732 - val_loss: -0.7636 - val_dice_coef: 0.7636\n",
      "\n",
      "Epoch 00262: val_loss did not improve from -0.76870\n",
      "Epoch 263/400\n",
      "37/37 [==============================] - 456s 12s/step - loss: -0.7793 - dice_coef: 0.7793 - val_loss: -0.7471 - val_dice_coef: 0.7471\n",
      "\n",
      "Epoch 00263: val_loss did not improve from -0.76870\n",
      "Epoch 264/400\n",
      "37/37 [==============================] - 463s 13s/step - loss: -0.7740 - dice_coef: 0.7740 - val_loss: -0.7637 - val_dice_coef: 0.7637\n",
      "\n",
      "Epoch 00264: val_loss did not improve from -0.76870\n",
      "Epoch 265/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7778 - dice_coef: 0.7778 - val_loss: -0.7623 - val_dice_coef: 0.7623\n",
      "\n",
      "Epoch 00265: val_loss did not improve from -0.76870\n",
      "Epoch 266/400\n",
      "37/37 [==============================] - 460s 12s/step - loss: -0.7799 - dice_coef: 0.7799 - val_loss: -0.7547 - val_dice_coef: 0.7547\n",
      "\n",
      "Epoch 00266: val_loss did not improve from -0.76870\n",
      "Epoch 267/400\n",
      "37/37 [==============================] - 458s 12s/step - loss: -0.7780 - dice_coef: 0.7780 - val_loss: -0.7430 - val_dice_coef: 0.7430\n",
      "\n",
      "Epoch 00267: val_loss did not improve from -0.76870\n",
      "Epoch 268/400\n",
      "37/37 [==============================] - 459s 12s/step - loss: -0.7860 - dice_coef: 0.7860 - val_loss: -0.7597 - val_dice_coef: 0.7597\n",
      "\n",
      "Epoch 00268: val_loss did not improve from -0.76870\n",
      "Epoch 269/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7815 - dice_coef: 0.7815 - val_loss: -0.7536 - val_dice_coef: 0.7536\n",
      "\n",
      "Epoch 00269: val_loss did not improve from -0.76870\n",
      "Epoch 270/400\n",
      "37/37 [==============================] - 474s 13s/step - loss: -0.7801 - dice_coef: 0.7801 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
      "\n",
      "Epoch 00270: val_loss did not improve from -0.76870\n",
      "Epoch 271/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 458s 12s/step - loss: -0.7840 - dice_coef: 0.7840 - val_loss: -0.7593 - val_dice_coef: 0.7593\n",
      "\n",
      "Epoch 00271: val_loss did not improve from -0.76870\n",
      "Epoch 272/400\n",
      "37/37 [==============================] - 463s 13s/step - loss: -0.7728 - dice_coef: 0.7728 - val_loss: -0.7561 - val_dice_coef: 0.7561\n",
      "\n",
      "Epoch 00272: val_loss did not improve from -0.76870\n",
      "Epoch 273/400\n",
      "37/37 [==============================] - 458s 12s/step - loss: -0.7749 - dice_coef: 0.7749 - val_loss: -0.7570 - val_dice_coef: 0.7570\n",
      "\n",
      "Epoch 00273: val_loss did not improve from -0.76870\n",
      "Epoch 274/400\n",
      "37/37 [==============================] - 460s 12s/step - loss: -0.7813 - dice_coef: 0.7813 - val_loss: -0.7588 - val_dice_coef: 0.7588\n",
      "\n",
      "Epoch 00274: val_loss did not improve from -0.76870\n",
      "Epoch 275/400\n",
      "37/37 [==============================] - 455s 12s/step - loss: -0.7821 - dice_coef: 0.7821 - val_loss: -0.7551 - val_dice_coef: 0.7551\n",
      "\n",
      "Epoch 00275: val_loss did not improve from -0.76870\n",
      "Epoch 276/400\n",
      "37/37 [==============================] - 460s 12s/step - loss: -0.7777 - dice_coef: 0.7777 - val_loss: -0.7467 - val_dice_coef: 0.7467\n",
      "\n",
      "Epoch 00276: val_loss did not improve from -0.76870\n",
      "Epoch 277/400\n",
      "37/37 [==============================] - 458s 12s/step - loss: -0.7842 - dice_coef: 0.7842 - val_loss: -0.7622 - val_dice_coef: 0.7622\n",
      "\n",
      "Epoch 00277: val_loss did not improve from -0.76870\n",
      "Epoch 278/400\n",
      "37/37 [==============================] - 456s 12s/step - loss: -0.7798 - dice_coef: 0.7798 - val_loss: -0.7728 - val_dice_coef: 0.7728\n",
      "\n",
      "Epoch 00278: val_loss improved from -0.76870 to -0.77275, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 279/400\n",
      "37/37 [==============================] - 460s 12s/step - loss: -0.7824 - dice_coef: 0.7824 - val_loss: -0.7606 - val_dice_coef: 0.7606\n",
      "\n",
      "Epoch 00279: val_loss did not improve from -0.77275\n",
      "Epoch 280/400\n",
      "37/37 [==============================] - 461s 12s/step - loss: -0.7794 - dice_coef: 0.7794 - val_loss: -0.7495 - val_dice_coef: 0.7495\n",
      "\n",
      "Epoch 00280: val_loss did not improve from -0.77275\n",
      "Epoch 281/400\n",
      "37/37 [==============================] - 456s 12s/step - loss: -0.7778 - dice_coef: 0.7778 - val_loss: -0.7674 - val_dice_coef: 0.7674\n",
      "\n",
      "Epoch 00281: val_loss did not improve from -0.77275\n",
      "Epoch 282/400\n",
      "37/37 [==============================] - 455s 12s/step - loss: -0.7825 - dice_coef: 0.7825 - val_loss: -0.7595 - val_dice_coef: 0.7595\n",
      "\n",
      "Epoch 00282: val_loss did not improve from -0.77275\n",
      "Epoch 283/400\n",
      "37/37 [==============================] - 455s 12s/step - loss: -0.7788 - dice_coef: 0.7788 - val_loss: -0.7469 - val_dice_coef: 0.7469\n",
      "\n",
      "Epoch 00283: val_loss did not improve from -0.77275\n",
      "Epoch 284/400\n",
      "37/37 [==============================] - 456s 12s/step - loss: -0.7780 - dice_coef: 0.7780 - val_loss: -0.7572 - val_dice_coef: 0.7572\n",
      "\n",
      "Epoch 00284: val_loss did not improve from -0.77275\n",
      "Epoch 285/400\n",
      "37/37 [==============================] - 454s 12s/step - loss: -0.7832 - dice_coef: 0.7832 - val_loss: -0.7584 - val_dice_coef: 0.7584\n",
      "\n",
      "Epoch 00285: val_loss did not improve from -0.77275\n",
      "Epoch 286/400\n",
      "37/37 [==============================] - 455s 12s/step - loss: -0.7782 - dice_coef: 0.7782 - val_loss: -0.7544 - val_dice_coef: 0.7544\n",
      "\n",
      "Epoch 00286: val_loss did not improve from -0.77275\n",
      "Epoch 287/400\n",
      "37/37 [==============================] - 455s 12s/step - loss: -0.7829 - dice_coef: 0.7829 - val_loss: -0.7520 - val_dice_coef: 0.7520\n",
      "\n",
      "Epoch 00287: val_loss did not improve from -0.77275\n",
      "Epoch 288/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7844 - dice_coef: 0.7844 - val_loss: -0.7590 - val_dice_coef: 0.7590\n",
      "\n",
      "Epoch 00288: val_loss did not improve from -0.77275\n",
      "Epoch 289/400\n",
      "37/37 [==============================] - 457s 12s/step - loss: -0.7803 - dice_coef: 0.7803 - val_loss: -0.7424 - val_dice_coef: 0.7424\n",
      "\n",
      "Epoch 00289: val_loss did not improve from -0.77275\n",
      "Epoch 290/400\n",
      "37/37 [==============================] - 492s 13s/step - loss: -0.7805 - dice_coef: 0.7805 - val_loss: -0.7543 - val_dice_coef: 0.7543\n",
      "\n",
      "Epoch 00290: val_loss did not improve from -0.77275\n",
      "Epoch 291/400\n",
      "37/37 [==============================] - 461s 12s/step - loss: -0.7828 - dice_coef: 0.7828 - val_loss: -0.7568 - val_dice_coef: 0.7568\n",
      "\n",
      "Epoch 00291: val_loss did not improve from -0.77275\n",
      "Epoch 292/400\n",
      "37/37 [==============================] - 463s 13s/step - loss: -0.7823 - dice_coef: 0.7823 - val_loss: -0.7628 - val_dice_coef: 0.7628\n",
      "\n",
      "Epoch 00292: val_loss did not improve from -0.77275\n",
      "Epoch 293/400\n",
      "37/37 [==============================] - 462s 12s/step - loss: -0.7826 - dice_coef: 0.7826 - val_loss: -0.7670 - val_dice_coef: 0.7670\n",
      "\n",
      "Epoch 00293: val_loss did not improve from -0.77275\n",
      "Epoch 294/400\n",
      "37/37 [==============================] - 461s 12s/step - loss: -0.7878 - dice_coef: 0.7878 - val_loss: -0.7598 - val_dice_coef: 0.7598\n",
      "\n",
      "Epoch 00294: val_loss did not improve from -0.77275\n",
      "Epoch 295/400\n",
      "37/37 [==============================] - 461s 12s/step - loss: -0.7791 - dice_coef: 0.7791 - val_loss: -0.7598 - val_dice_coef: 0.7598\n",
      "\n",
      "Epoch 00295: val_loss did not improve from -0.77275\n",
      "Epoch 296/400\n",
      "37/37 [==============================] - 565s 15s/step - loss: -0.7873 - dice_coef: 0.7873 - val_loss: -0.7654 - val_dice_coef: 0.7654\n",
      "\n",
      "Epoch 00296: val_loss did not improve from -0.77275\n",
      "Epoch 297/400\n",
      "37/37 [==============================] - 636s 17s/step - loss: -0.7819 - dice_coef: 0.7819 - val_loss: -0.7537 - val_dice_coef: 0.7537\n",
      "\n",
      "Epoch 00297: val_loss did not improve from -0.77275\n",
      "Epoch 298/400\n",
      "37/37 [==============================] - 570s 15s/step - loss: -0.7909 - dice_coef: 0.7909 - val_loss: -0.7604 - val_dice_coef: 0.7604\n",
      "\n",
      "Epoch 00298: val_loss did not improve from -0.77275\n",
      "Epoch 299/400\n",
      "37/37 [==============================] - 604s 16s/step - loss: -0.7857 - dice_coef: 0.7857 - val_loss: -0.7586 - val_dice_coef: 0.7586\n",
      "\n",
      "Epoch 00299: val_loss did not improve from -0.77275\n",
      "Epoch 300/400\n",
      "37/37 [==============================] - 755s 20s/step - loss: -0.7841 - dice_coef: 0.7841 - val_loss: -0.7667 - val_dice_coef: 0.7667\n",
      "\n",
      "Epoch 00300: val_loss did not improve from -0.77275\n",
      "Epoch 301/400\n",
      "37/37 [==============================] - 673s 18s/step - loss: -0.7871 - dice_coef: 0.7871 - val_loss: -0.7649 - val_dice_coef: 0.7649\n",
      "\n",
      "Epoch 00301: val_loss did not improve from -0.77275\n",
      "Epoch 302/400\n",
      "37/37 [==============================] - 697s 19s/step - loss: -0.7823 - dice_coef: 0.7823 - val_loss: -0.7524 - val_dice_coef: 0.7524\n",
      "\n",
      "Epoch 00302: val_loss did not improve from -0.77275\n",
      "Epoch 303/400\n",
      "37/37 [==============================] - 739s 20s/step - loss: -0.7801 - dice_coef: 0.7801 - val_loss: -0.7546 - val_dice_coef: 0.7546\n",
      "\n",
      "Epoch 00303: val_loss did not improve from -0.77275\n",
      "Epoch 304/400\n",
      "37/37 [==============================] - 592s 16s/step - loss: -0.7798 - dice_coef: 0.7798 - val_loss: -0.7711 - val_dice_coef: 0.7711\n",
      "\n",
      "Epoch 00304: val_loss did not improve from -0.77275\n",
      "Epoch 305/400\n",
      "37/37 [==============================] - 632s 17s/step - loss: -0.7858 - dice_coef: 0.7858 - val_loss: -0.7580 - val_dice_coef: 0.7580\n",
      "\n",
      "Epoch 00305: val_loss did not improve from -0.77275\n",
      "Epoch 306/400\n",
      "37/37 [==============================] - 677s 18s/step - loss: -0.7846 - dice_coef: 0.7846 - val_loss: -0.7539 - val_dice_coef: 0.7539\n",
      "\n",
      "Epoch 00306: val_loss did not improve from -0.77275\n",
      "Epoch 307/400\n",
      "37/37 [==============================] - 530s 14s/step - loss: -0.7828 - dice_coef: 0.7828 - val_loss: -0.7620 - val_dice_coef: 0.7620\n",
      "\n",
      "Epoch 00307: val_loss did not improve from -0.77275\n",
      "Epoch 308/400\n",
      "37/37 [==============================] - 481s 13s/step - loss: -0.7803 - dice_coef: 0.7803 - val_loss: -0.7619 - val_dice_coef: 0.7619\n",
      "\n",
      "Epoch 00308: val_loss did not improve from -0.77275\n",
      "Epoch 309/400\n",
      "37/37 [==============================] - 486s 13s/step - loss: -0.7805 - dice_coef: 0.7805 - val_loss: -0.7617 - val_dice_coef: 0.7617\n",
      "\n",
      "Epoch 00309: val_loss did not improve from -0.77275\n",
      "Epoch 310/400\n",
      "37/37 [==============================] - 480s 13s/step - loss: -0.7873 - dice_coef: 0.7873 - val_loss: -0.7666 - val_dice_coef: 0.7666\n",
      "\n",
      "Epoch 00310: val_loss did not improve from -0.77275\n",
      "Epoch 311/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 480s 13s/step - loss: -0.7877 - dice_coef: 0.7877 - val_loss: -0.7666 - val_dice_coef: 0.7666\n",
      "\n",
      "Epoch 00311: val_loss did not improve from -0.77275\n",
      "Epoch 312/400\n",
      "37/37 [==============================] - 479s 13s/step - loss: -0.7852 - dice_coef: 0.7852 - val_loss: -0.7633 - val_dice_coef: 0.7633\n",
      "\n",
      "Epoch 00312: val_loss did not improve from -0.77275\n",
      "Epoch 313/400\n",
      "37/37 [==============================] - 479s 13s/step - loss: -0.7786 - dice_coef: 0.7786 - val_loss: -0.7501 - val_dice_coef: 0.7501\n",
      "\n",
      "Epoch 00313: val_loss did not improve from -0.77275\n",
      "Epoch 314/400\n",
      "37/37 [==============================] - 483s 13s/step - loss: -0.7730 - dice_coef: 0.7730 - val_loss: -0.7480 - val_dice_coef: 0.7480\n",
      "\n",
      "Epoch 00314: val_loss did not improve from -0.77275\n",
      "Epoch 315/400\n",
      "37/37 [==============================] - 481s 13s/step - loss: -0.7858 - dice_coef: 0.7858 - val_loss: -0.7443 - val_dice_coef: 0.7443\n",
      "\n",
      "Epoch 00315: val_loss did not improve from -0.77275\n",
      "Epoch 316/400\n",
      "37/37 [==============================] - 482s 13s/step - loss: -0.7835 - dice_coef: 0.7835 - val_loss: -0.7571 - val_dice_coef: 0.7571\n",
      "\n",
      "Epoch 00316: val_loss did not improve from -0.77275\n",
      "Epoch 317/400\n",
      "37/37 [==============================] - 482s 13s/step - loss: -0.7834 - dice_coef: 0.7834 - val_loss: -0.7566 - val_dice_coef: 0.7566\n",
      "\n",
      "Epoch 00317: val_loss did not improve from -0.77275\n",
      "Epoch 318/400\n",
      "37/37 [==============================] - 485s 13s/step - loss: -0.7856 - dice_coef: 0.7856 - val_loss: -0.7649 - val_dice_coef: 0.7649\n",
      "\n",
      "Epoch 00318: val_loss did not improve from -0.77275\n",
      "Epoch 319/400\n",
      "37/37 [==============================] - 483s 13s/step - loss: -0.7889 - dice_coef: 0.7889 - val_loss: -0.7615 - val_dice_coef: 0.7615\n",
      "\n",
      "Epoch 00319: val_loss did not improve from -0.77275\n",
      "Epoch 320/400\n",
      "37/37 [==============================] - 484s 13s/step - loss: -0.7863 - dice_coef: 0.7863 - val_loss: -0.7711 - val_dice_coef: 0.7711\n",
      "\n",
      "Epoch 00320: val_loss did not improve from -0.77275\n",
      "Epoch 321/400\n",
      "37/37 [==============================] - 486s 13s/step - loss: -0.7883 - dice_coef: 0.7883 - val_loss: -0.7586 - val_dice_coef: 0.7586\n",
      "\n",
      "Epoch 00321: val_loss did not improve from -0.77275\n",
      "Epoch 322/400\n",
      "37/37 [==============================] - 486s 13s/step - loss: -0.7912 - dice_coef: 0.7912 - val_loss: -0.7658 - val_dice_coef: 0.7658\n",
      "\n",
      "Epoch 00322: val_loss did not improve from -0.77275\n",
      "Epoch 323/400\n",
      "37/37 [==============================] - 484s 13s/step - loss: -0.7899 - dice_coef: 0.7899 - val_loss: -0.7656 - val_dice_coef: 0.7656\n",
      "\n",
      "Epoch 00323: val_loss did not improve from -0.77275\n",
      "Epoch 324/400\n",
      "37/37 [==============================] - 489s 13s/step - loss: -0.7908 - dice_coef: 0.7908 - val_loss: -0.7618 - val_dice_coef: 0.7618\n",
      "\n",
      "Epoch 00324: val_loss did not improve from -0.77275\n",
      "Epoch 325/400\n",
      "37/37 [==============================] - 486s 13s/step - loss: -0.7897 - dice_coef: 0.7897 - val_loss: -0.7549 - val_dice_coef: 0.7549\n",
      "\n",
      "Epoch 00325: val_loss did not improve from -0.77275\n",
      "Epoch 326/400\n",
      "37/37 [==============================] - 485s 13s/step - loss: -0.7926 - dice_coef: 0.7926 - val_loss: -0.7647 - val_dice_coef: 0.7647\n",
      "\n",
      "Epoch 00326: val_loss did not improve from -0.77275\n",
      "Epoch 327/400\n",
      "37/37 [==============================] - 484s 13s/step - loss: -0.7875 - dice_coef: 0.7875 - val_loss: -0.7630 - val_dice_coef: 0.7630\n",
      "\n",
      "Epoch 00327: val_loss did not improve from -0.77275\n",
      "Epoch 328/400\n",
      "37/37 [==============================] - 492s 13s/step - loss: -0.7892 - dice_coef: 0.7892 - val_loss: -0.7670 - val_dice_coef: 0.7670\n",
      "\n",
      "Epoch 00328: val_loss did not improve from -0.77275\n",
      "Epoch 329/400\n",
      "37/37 [==============================] - 489s 13s/step - loss: -0.7872 - dice_coef: 0.7872 - val_loss: -0.7588 - val_dice_coef: 0.7588\n",
      "\n",
      "Epoch 00329: val_loss did not improve from -0.77275\n",
      "Epoch 330/400\n",
      "37/37 [==============================] - 486s 13s/step - loss: -0.7892 - dice_coef: 0.7892 - val_loss: -0.7448 - val_dice_coef: 0.7448\n",
      "\n",
      "Epoch 00330: val_loss did not improve from -0.77275\n",
      "Epoch 331/400\n",
      "37/37 [==============================] - 491s 13s/step - loss: -0.7892 - dice_coef: 0.7892 - val_loss: -0.7587 - val_dice_coef: 0.7587\n",
      "\n",
      "Epoch 00331: val_loss did not improve from -0.77275\n",
      "Epoch 332/400\n",
      "37/37 [==============================] - 491s 13s/step - loss: -0.7844 - dice_coef: 0.7844 - val_loss: -0.7567 - val_dice_coef: 0.7567\n",
      "\n",
      "Epoch 00332: val_loss did not improve from -0.77275\n",
      "Epoch 333/400\n",
      "37/37 [==============================] - 488s 13s/step - loss: -0.7820 - dice_coef: 0.7820 - val_loss: -0.7538 - val_dice_coef: 0.7538\n",
      "\n",
      "Epoch 00333: val_loss did not improve from -0.77275\n",
      "Epoch 334/400\n",
      "37/37 [==============================] - 486s 13s/step - loss: -0.7932 - dice_coef: 0.7932 - val_loss: -0.7646 - val_dice_coef: 0.7646\n",
      "\n",
      "Epoch 00334: val_loss did not improve from -0.77275\n",
      "Epoch 335/400\n",
      "37/37 [==============================] - 487s 13s/step - loss: -0.7810 - dice_coef: 0.7810 - val_loss: -0.7455 - val_dice_coef: 0.7455\n",
      "\n",
      "Epoch 00335: val_loss did not improve from -0.77275\n",
      "Epoch 336/400\n",
      "37/37 [==============================] - 558s 15s/step - loss: -0.7886 - dice_coef: 0.7886 - val_loss: -0.7677 - val_dice_coef: 0.7677\n",
      "\n",
      "Epoch 00336: val_loss did not improve from -0.77275\n",
      "Epoch 337/400\n",
      "37/37 [==============================] - 531s 14s/step - loss: -0.7906 - dice_coef: 0.7906 - val_loss: -0.7535 - val_dice_coef: 0.7535\n",
      "\n",
      "Epoch 00337: val_loss did not improve from -0.77275\n",
      "Epoch 338/400\n",
      "37/37 [==============================] - 545s 15s/step - loss: -0.7891 - dice_coef: 0.7891 - val_loss: -0.7673 - val_dice_coef: 0.7673\n",
      "\n",
      "Epoch 00338: val_loss did not improve from -0.77275\n",
      "Epoch 339/400\n",
      "37/37 [==============================] - 513s 14s/step - loss: -0.7939 - dice_coef: 0.7939 - val_loss: -0.7573 - val_dice_coef: 0.7573\n",
      "\n",
      "Epoch 00339: val_loss did not improve from -0.77275\n",
      "Epoch 340/400\n",
      "37/37 [==============================] - 471s 13s/step - loss: -0.7873 - dice_coef: 0.7873 - val_loss: -0.7616 - val_dice_coef: 0.7616\n",
      "\n",
      "Epoch 00340: val_loss did not improve from -0.77275\n",
      "Epoch 341/400\n",
      "37/37 [==============================] - 471s 13s/step - loss: -0.7921 - dice_coef: 0.7921 - val_loss: -0.7499 - val_dice_coef: 0.7499\n",
      "\n",
      "Epoch 00341: val_loss did not improve from -0.77275\n",
      "Epoch 342/400\n",
      "37/37 [==============================] - 469s 13s/step - loss: -0.7925 - dice_coef: 0.7925 - val_loss: -0.7635 - val_dice_coef: 0.7635\n",
      "\n",
      "Epoch 00342: val_loss did not improve from -0.77275\n",
      "Epoch 343/400\n",
      "37/37 [==============================] - 566s 15s/step - loss: -0.7788 - dice_coef: 0.7788 - val_loss: -0.7474 - val_dice_coef: 0.7474\n",
      "\n",
      "Epoch 00343: val_loss did not improve from -0.77275\n",
      "Epoch 344/400\n",
      "37/37 [==============================] - 577s 16s/step - loss: -0.7814 - dice_coef: 0.7814 - val_loss: -0.7552 - val_dice_coef: 0.7552\n",
      "\n",
      "Epoch 00344: val_loss did not improve from -0.77275\n",
      "Epoch 345/400\n",
      "37/37 [==============================] - 480s 13s/step - loss: -0.7851 - dice_coef: 0.7851 - val_loss: -0.7703 - val_dice_coef: 0.7703\n",
      "\n",
      "Epoch 00345: val_loss did not improve from -0.77275\n",
      "Epoch 346/400\n",
      "37/37 [==============================] - 496s 13s/step - loss: -0.7923 - dice_coef: 0.7923 - val_loss: -0.7516 - val_dice_coef: 0.7516\n",
      "\n",
      "Epoch 00346: val_loss did not improve from -0.77275\n",
      "Epoch 347/400\n",
      "37/37 [==============================] - 555s 15s/step - loss: -0.7802 - dice_coef: 0.7802 - val_loss: -0.7606 - val_dice_coef: 0.7606\n",
      "\n",
      "Epoch 00347: val_loss did not improve from -0.77275\n",
      "Epoch 348/400\n",
      "37/37 [==============================] - 482s 13s/step - loss: -0.7861 - dice_coef: 0.7861 - val_loss: -0.7598 - val_dice_coef: 0.7598\n",
      "\n",
      "Epoch 00348: val_loss did not improve from -0.77275\n",
      "Epoch 349/400\n",
      "37/37 [==============================] - 566s 15s/step - loss: -0.7895 - dice_coef: 0.7895 - val_loss: -0.7650 - val_dice_coef: 0.7650\n",
      "\n",
      "Epoch 00349: val_loss did not improve from -0.77275\n",
      "Epoch 350/400\n",
      "37/37 [==============================] - 489s 13s/step - loss: -0.7829 - dice_coef: 0.7829 - val_loss: -0.7449 - val_dice_coef: 0.7449\n",
      "\n",
      "Epoch 00350: val_loss did not improve from -0.77275\n",
      "Epoch 351/400\n",
      "37/37 [==============================] - 461s 12s/step - loss: -0.7905 - dice_coef: 0.7905 - val_loss: -0.7619 - val_dice_coef: 0.7619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00351: val_loss did not improve from -0.77275\n",
      "Epoch 352/400\n",
      "37/37 [==============================] - 460s 12s/step - loss: -0.7847 - dice_coef: 0.7847 - val_loss: -0.7683 - val_dice_coef: 0.7683\n",
      "\n",
      "Epoch 00352: val_loss did not improve from -0.77275\n",
      "Epoch 353/400\n",
      "37/37 [==============================] - 532s 14s/step - loss: -0.7865 - dice_coef: 0.7865 - val_loss: -0.7660 - val_dice_coef: 0.7660\n",
      "\n",
      "Epoch 00353: val_loss did not improve from -0.77275\n",
      "Epoch 354/400\n",
      "37/37 [==============================] - 556s 15s/step - loss: -0.7913 - dice_coef: 0.7913 - val_loss: -0.7745 - val_dice_coef: 0.7745\n",
      "\n",
      "Epoch 00354: val_loss improved from -0.77275 to -0.77446, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 355/400\n",
      "37/37 [==============================] - 523s 14s/step - loss: -0.7897 - dice_coef: 0.7897 - val_loss: -0.7659 - val_dice_coef: 0.7659\n",
      "\n",
      "Epoch 00355: val_loss did not improve from -0.77446\n",
      "Epoch 356/400\n",
      "37/37 [==============================] - 514s 14s/step - loss: -0.7911 - dice_coef: 0.7911 - val_loss: -0.7598 - val_dice_coef: 0.7598\n",
      "\n",
      "Epoch 00356: val_loss did not improve from -0.77446\n",
      "Epoch 357/400\n",
      "37/37 [==============================] - 508s 14s/step - loss: -0.7914 - dice_coef: 0.7914 - val_loss: -0.7565 - val_dice_coef: 0.7565\n",
      "\n",
      "Epoch 00357: val_loss did not improve from -0.77446\n",
      "Epoch 358/400\n",
      "37/37 [==============================] - 510s 14s/step - loss: -0.7947 - dice_coef: 0.7947 - val_loss: -0.7688 - val_dice_coef: 0.7688\n",
      "\n",
      "Epoch 00358: val_loss did not improve from -0.77446\n",
      "Epoch 359/400\n",
      "37/37 [==============================] - 607s 16s/step - loss: -0.7967 - dice_coef: 0.7967 - val_loss: -0.7762 - val_dice_coef: 0.7762\n",
      "\n",
      "Epoch 00359: val_loss improved from -0.77446 to -0.77623, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 360/400\n",
      "37/37 [==============================] - 576s 16s/step - loss: -0.7979 - dice_coef: 0.7979 - val_loss: -0.7550 - val_dice_coef: 0.7550\n",
      "\n",
      "Epoch 00360: val_loss did not improve from -0.77623\n",
      "Epoch 361/400\n",
      "37/37 [==============================] - 589s 16s/step - loss: -0.7911 - dice_coef: 0.7911 - val_loss: -0.7689 - val_dice_coef: 0.7689\n",
      "\n",
      "Epoch 00361: val_loss did not improve from -0.77623\n",
      "Epoch 362/400\n",
      "37/37 [==============================] - 509s 14s/step - loss: -0.7952 - dice_coef: 0.7952 - val_loss: -0.7569 - val_dice_coef: 0.7569\n",
      "\n",
      "Epoch 00362: val_loss did not improve from -0.77623\n",
      "Epoch 363/400\n",
      "37/37 [==============================] - 502s 14s/step - loss: -0.7880 - dice_coef: 0.7880 - val_loss: -0.7621 - val_dice_coef: 0.7621\n",
      "\n",
      "Epoch 00363: val_loss did not improve from -0.77623\n",
      "Epoch 364/400\n",
      "37/37 [==============================] - 546s 15s/step - loss: -0.7891 - dice_coef: 0.7891 - val_loss: -0.7786 - val_dice_coef: 0.7786\n",
      "\n",
      "Epoch 00364: val_loss improved from -0.77623 to -0.77860, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 365/400\n",
      "37/37 [==============================] - 523s 14s/step - loss: -0.7904 - dice_coef: 0.7904 - val_loss: -0.7655 - val_dice_coef: 0.7655\n",
      "\n",
      "Epoch 00365: val_loss did not improve from -0.77860\n",
      "Epoch 366/400\n",
      "37/37 [==============================] - 571s 15s/step - loss: -0.7896 - dice_coef: 0.7896 - val_loss: -0.7622 - val_dice_coef: 0.7622\n",
      "\n",
      "Epoch 00366: val_loss did not improve from -0.77860\n",
      "Epoch 367/400\n",
      "37/37 [==============================] - 548s 15s/step - loss: -0.7925 - dice_coef: 0.7925 - val_loss: -0.7655 - val_dice_coef: 0.7655\n",
      "\n",
      "Epoch 00367: val_loss did not improve from -0.77860\n",
      "Epoch 368/400\n",
      "37/37 [==============================] - 509s 14s/step - loss: -0.7950 - dice_coef: 0.7950 - val_loss: -0.7796 - val_dice_coef: 0.7796\n",
      "\n",
      "Epoch 00368: val_loss improved from -0.77860 to -0.77963, saving model to unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5\n",
      "Epoch 369/400\n",
      "37/37 [==============================] - 539s 15s/step - loss: -0.7921 - dice_coef: 0.7921 - val_loss: -0.7652 - val_dice_coef: 0.7652\n",
      "\n",
      "Epoch 00369: val_loss did not improve from -0.77963\n",
      "Epoch 370/400\n",
      "37/37 [==============================] - 559s 15s/step - loss: -0.7882 - dice_coef: 0.7882 - val_loss: -0.7646 - val_dice_coef: 0.7646\n",
      "\n",
      "Epoch 00370: val_loss did not improve from -0.77963\n",
      "Epoch 371/400\n",
      "37/37 [==============================] - 539s 15s/step - loss: -0.7930 - dice_coef: 0.7930 - val_loss: -0.7703 - val_dice_coef: 0.7703\n",
      "\n",
      "Epoch 00371: val_loss did not improve from -0.77963\n",
      "Epoch 372/400\n",
      "37/37 [==============================] - 534s 14s/step - loss: -0.7926 - dice_coef: 0.7926 - val_loss: -0.7634 - val_dice_coef: 0.7634\n",
      "\n",
      "Epoch 00372: val_loss did not improve from -0.77963\n",
      "Epoch 373/400\n",
      "37/37 [==============================] - 522s 14s/step - loss: -0.7972 - dice_coef: 0.7972 - val_loss: -0.7592 - val_dice_coef: 0.7592\n",
      "\n",
      "Epoch 00373: val_loss did not improve from -0.77963\n",
      "Epoch 374/400\n",
      "37/37 [==============================] - 560s 15s/step - loss: -0.7903 - dice_coef: 0.7903 - val_loss: -0.7610 - val_dice_coef: 0.7610\n",
      "\n",
      "Epoch 00374: val_loss did not improve from -0.77963\n",
      "Epoch 375/400\n",
      "37/37 [==============================] - 532s 14s/step - loss: -0.7899 - dice_coef: 0.7899 - val_loss: -0.7650 - val_dice_coef: 0.7650\n",
      "\n",
      "Epoch 00375: val_loss did not improve from -0.77963\n",
      "Epoch 376/400\n",
      "37/37 [==============================] - 476s 13s/step - loss: -0.7910 - dice_coef: 0.7910 - val_loss: -0.7565 - val_dice_coef: 0.7565\n",
      "\n",
      "Epoch 00376: val_loss did not improve from -0.77963\n",
      "Epoch 377/400\n",
      "37/37 [==============================] - 478s 13s/step - loss: -0.7923 - dice_coef: 0.7923 - val_loss: -0.7512 - val_dice_coef: 0.7512\n",
      "\n",
      "Epoch 00377: val_loss did not improve from -0.77963\n",
      "Epoch 378/400\n",
      "37/37 [==============================] - 634s 17s/step - loss: -0.7845 - dice_coef: 0.7845 - val_loss: -0.7507 - val_dice_coef: 0.7507\n",
      "\n",
      "Epoch 00378: val_loss did not improve from -0.77963\n",
      "Epoch 379/400\n",
      "37/37 [==============================] - 612s 17s/step - loss: -0.7830 - dice_coef: 0.7830 - val_loss: -0.7712 - val_dice_coef: 0.7712\n",
      "\n",
      "Epoch 00379: val_loss did not improve from -0.77963\n",
      "Epoch 380/400\n",
      "37/37 [==============================] - 585s 16s/step - loss: -0.7933 - dice_coef: 0.7933 - val_loss: -0.7500 - val_dice_coef: 0.7500\n",
      "\n",
      "Epoch 00380: val_loss did not improve from -0.77963\n",
      "Epoch 381/400\n",
      "37/37 [==============================] - 601s 16s/step - loss: -0.7971 - dice_coef: 0.7971 - val_loss: -0.7564 - val_dice_coef: 0.7564\n",
      "\n",
      "Epoch 00381: val_loss did not improve from -0.77963\n",
      "Epoch 382/400\n",
      "37/37 [==============================] - 630s 17s/step - loss: -0.7918 - dice_coef: 0.7918 - val_loss: -0.7628 - val_dice_coef: 0.7628\n",
      "\n",
      "Epoch 00382: val_loss did not improve from -0.77963\n",
      "Epoch 383/400\n",
      "37/37 [==============================] - 577s 16s/step - loss: -0.7978 - dice_coef: 0.7978 - val_loss: -0.7667 - val_dice_coef: 0.7667\n",
      "\n",
      "Epoch 00383: val_loss did not improve from -0.77963\n",
      "Epoch 384/400\n",
      "37/37 [==============================] - 561s 15s/step - loss: -0.8008 - dice_coef: 0.8008 - val_loss: -0.7666 - val_dice_coef: 0.7666\n",
      "\n",
      "Epoch 00384: val_loss did not improve from -0.77963\n",
      "Epoch 385/400\n",
      "37/37 [==============================] - 450s 12s/step - loss: -0.7879 - dice_coef: 0.7879 - val_loss: -0.7610 - val_dice_coef: 0.7610\n",
      "\n",
      "Epoch 00385: val_loss did not improve from -0.77963\n",
      "Epoch 386/400\n",
      "37/37 [==============================] - 453s 12s/step - loss: -0.7925 - dice_coef: 0.7925 - val_loss: -0.7702 - val_dice_coef: 0.7702\n",
      "\n",
      "Epoch 00386: val_loss did not improve from -0.77963\n",
      "Epoch 387/400\n",
      "37/37 [==============================] - 455s 12s/step - loss: -0.7957 - dice_coef: 0.7957 - val_loss: -0.7479 - val_dice_coef: 0.7479\n",
      "\n",
      "Epoch 00387: val_loss did not improve from -0.77963\n",
      "Epoch 388/400\n",
      "37/37 [==============================] - 452s 12s/step - loss: -0.7947 - dice_coef: 0.7947 - val_loss: -0.7588 - val_dice_coef: 0.7588\n",
      "\n",
      "Epoch 00388: val_loss did not improve from -0.77963\n",
      "Epoch 389/400\n",
      "37/37 [==============================] - 451s 12s/step - loss: -0.7903 - dice_coef: 0.7903 - val_loss: -0.7610 - val_dice_coef: 0.7610\n",
      "\n",
      "Epoch 00389: val_loss did not improve from -0.77963\n",
      "Epoch 390/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 449s 12s/step - loss: -0.7895 - dice_coef: 0.7895 - val_loss: -0.7537 - val_dice_coef: 0.7537\n",
      "\n",
      "Epoch 00390: val_loss did not improve from -0.77963\n",
      "Epoch 391/400\n",
      "37/37 [==============================] - 456s 12s/step - loss: -0.7932 - dice_coef: 0.7932 - val_loss: -0.7493 - val_dice_coef: 0.7493\n",
      "\n",
      "Epoch 00391: val_loss did not improve from -0.77963\n",
      "Epoch 392/400\n",
      "37/37 [==============================] - 454s 12s/step - loss: -0.7929 - dice_coef: 0.7929 - val_loss: -0.7525 - val_dice_coef: 0.7525\n",
      "\n",
      "Epoch 00392: val_loss did not improve from -0.77963\n",
      "Epoch 393/400\n",
      "37/37 [==============================] - 452s 12s/step - loss: -0.7953 - dice_coef: 0.7953 - val_loss: -0.7576 - val_dice_coef: 0.7576\n",
      "\n",
      "Epoch 00393: val_loss did not improve from -0.77963\n",
      "Epoch 394/400\n",
      "37/37 [==============================] - 452s 12s/step - loss: -0.7919 - dice_coef: 0.7919 - val_loss: -0.7586 - val_dice_coef: 0.7586\n",
      "\n",
      "Epoch 00394: val_loss did not improve from -0.77963\n",
      "Epoch 395/400\n",
      "37/37 [==============================] - 454s 12s/step - loss: -0.7914 - dice_coef: 0.7914 - val_loss: -0.7609 - val_dice_coef: 0.7609\n",
      "\n",
      "Epoch 00395: val_loss did not improve from -0.77963\n",
      "Epoch 396/400\n",
      "37/37 [==============================] - 453s 12s/step - loss: -0.8012 - dice_coef: 0.8012 - val_loss: -0.7628 - val_dice_coef: 0.7628\n",
      "\n",
      "Epoch 00396: val_loss did not improve from -0.77963\n",
      "Epoch 397/400\n",
      "37/37 [==============================] - 454s 12s/step - loss: -0.7914 - dice_coef: 0.7914 - val_loss: -0.7622 - val_dice_coef: 0.7622\n",
      "\n",
      "Epoch 00397: val_loss did not improve from -0.77963\n",
      "Epoch 398/400\n",
      "37/37 [==============================] - 453s 12s/step - loss: -0.7927 - dice_coef: 0.7927 - val_loss: -0.7685 - val_dice_coef: 0.7685\n",
      "\n",
      "Epoch 00398: val_loss did not improve from -0.77963\n",
      "Epoch 399/400\n",
      "37/37 [==============================] - 455s 12s/step - loss: -0.7905 - dice_coef: 0.7905 - val_loss: -0.7731 - val_dice_coef: 0.7731\n",
      "\n",
      "Epoch 00399: val_loss did not improve from -0.77963\n",
      "Epoch 400/400\n",
      "37/37 [==============================] - 453s 12s/step - loss: -0.7986 - dice_coef: 0.7986 - val_loss: -0.7557 - val_dice_coef: 0.7557\n",
      "\n",
      "Epoch 00400: val_loss did not improve from -0.77963\n",
      "dict_keys(['val_loss', 'val_dice_coef', 'loss', 'dice_coef'])\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import math\n",
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "from PIL import ImageFile\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # To allow premature JPG\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "    if not os.path.exists('./' + info):\n",
    "        os.makedirs('./' + info)\n",
    "\n",
    "    UNET_IMAGE_FORMAT = '*.png'\n",
    "\n",
    "    nbr_train_samples = len(glob.glob(os.path.join(UNET_TRAIN_SPLIT_FOLDER, '*', UNET_IMAGE_FORMAT)))\n",
    "    nbr_validation_samples = len(glob.glob(os.path.join(UNET_VAL_SPLIT_FOLDER, '*', UNET_IMAGE_FORMAT)))\n",
    "\n",
    "    # autosave best Model\n",
    "    best_model_file = os.path.join(info, 'weights.h5')\n",
    "    best_model = ModelCheckpoint(best_model_file, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "    if os.path.exists(best_model_file):\n",
    "        print('WARNING: Resume model and weights from previous training ...')\n",
    "        # Backup previous model file\n",
    "        copyfile(best_model_file, best_model_file + '.' + getTimestamp())\n",
    "        model = load_model(img_height, img_width, nb_channels, learning_rate, best_model_file)\n",
    "        model.summary()\n",
    "    else:\n",
    "        print('Using UNET impls  ... save best model to:{}'.format(best_model_file))\n",
    "        model = create_model(img_height, img_width, nb_channels, learning_rate)\n",
    "        model.summary()\n",
    "\n",
    "    steps_per_epoch = math.ceil(1. * nbr_train_samples / batch_size)\n",
    "    validation_steps = math.ceil(1. * nbr_validation_samples / batch_size)\n",
    "    print('steps_per_epoch={} , validation_steps={} epochs={}'.format(steps_per_epoch, validation_steps, nbr_epochs))\n",
    "    if steps_per_epoch <= 0:\n",
    "        raise AssertionError(\"Found 0 train samples\")\n",
    "    if validation_steps <= 0:\n",
    "        raise AssertionError(\"Found 0 validation samples\")\n",
    "\n",
    "\n",
    "    train_generator = getCombinedImageDataGenerator(\n",
    "        x_folder=UNET_TRAIN_SPLIT_FOLDER,\n",
    "        y_folder=UNET_TRAINMASK_SPLIT_FOLDER\n",
    "    )\n",
    "    validation_generator = getCombinedImageDataGenerator(\n",
    "        x_folder=UNET_VAL_SPLIT_FOLDER,\n",
    "        y_folder=UNET_VALMASK_SPLIT_FOLDER\n",
    "    )\n",
    "\n",
    "    print('Start training using ImageDataGenerator:')\n",
    "    history = model.fit_generator(\n",
    "        generator=train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=nbr_epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_steps,\n",
    "        callbacks=[best_model],\n",
    "        verbose=1)\n",
    "\n",
    "    save_training_history(info, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped 0/512 images\n",
      "Cropped 20/512 images\n",
      "Cropped 40/512 images\n",
      "Cropped 60/512 images\n",
      "Cropped 80/512 images\n",
      "Cropped 100/512 images\n",
      "Cropped 120/512 images\n",
      "Cropped 140/512 images\n",
      "Cropped 160/512 images\n",
      "Cropped 180/512 images\n",
      "Cropped 200/512 images\n",
      "Cropped 220/512 images\n",
      "Cropped 240/512 images\n",
      "Cropped 260/512 images\n",
      "Cropped 280/512 images\n",
      "Cropped 300/512 images\n",
      "Cropped 320/512 images\n",
      "Cropped 340/512 images\n",
      "Cropped 360/512 images\n",
      "Cropped 380/512 images\n",
      "Cropped 400/512 images\n",
      "Cropped 420/512 images\n",
      "Cropped 440/512 images\n",
      "Cropped 460/512 images\n",
      "Cropped 480/512 images\n",
      "Cropped 500/512 images\n"
     ]
    }
   ],
   "source": [
    "def maxHist(hist):\n",
    "    maxArea = (0, 0, 0)\n",
    "    height = []\n",
    "    position = []\n",
    "    for i in range(len(hist)):\n",
    "        if (len(height) == 0):\n",
    "            if (hist[i] > 0):\n",
    "                height.append(hist[i])\n",
    "                position.append(i)\n",
    "        else:\n",
    "            if (hist[i] > height[-1]):\n",
    "                height.append(hist[i])\n",
    "                position.append(i)\n",
    "            elif (hist[i] < height[-1]):\n",
    "                while (height[-1] > hist[i]):\n",
    "                    maxHeight = height.pop()\n",
    "                    area = maxHeight * (i - position[-1])\n",
    "                    if (area > maxArea[0]):\n",
    "                        maxArea = (area, position[-1], i)\n",
    "                    last_position = position.pop()\n",
    "                    if (len(height) == 0):\n",
    "                        break\n",
    "                position.append(last_position)\n",
    "                if (len(height) == 0):\n",
    "                    height.append(hist[i])\n",
    "                elif (height[-1] < hist[i]):\n",
    "                    height.append(hist[i])\n",
    "                else:\n",
    "                    position.pop()\n",
    "    while (len(height) > 0):\n",
    "        maxHeight = height.pop()\n",
    "        last_position = position.pop()\n",
    "        area = maxHeight * (len(hist) - last_position)\n",
    "        if (area > maxArea[0]):\n",
    "            maxArea = (area, len(hist), last_position)\n",
    "    return maxArea\n",
    "\n",
    "\n",
    "def maxRect(img):\n",
    "    maxArea = (0, 0, 0)\n",
    "    addMat = np.zeros(img.shape)\n",
    "    for r in range(img.shape[0]):\n",
    "        if r == 0:\n",
    "            addMat[r] = img[r]\n",
    "            area = maxHist(addMat[r])\n",
    "            if area[0] > maxArea[0]:\n",
    "                maxArea = area + (r,)\n",
    "        else:\n",
    "            addMat[r] = img[r] + addMat[r - 1]\n",
    "            addMat[r][img[r] == 0] *= 0\n",
    "            area = maxHist(addMat[r])\n",
    "            if area[0] > maxArea[0]:\n",
    "                maxArea = area + (r,)\n",
    "    return (\n",
    "        int(maxArea[3] + 1 - maxArea[0] / abs(maxArea[1] - maxArea[2])), maxArea[2], maxArea[3], maxArea[1], maxArea[0])\n",
    "\n",
    "\n",
    "def cropCircle(img, resize=None):\n",
    "    if resize:\n",
    "        if (img.shape[0] > img.shape[1]):\n",
    "            tile_size = (int(img.shape[1] * resize / img.shape[0]), resize)\n",
    "        else:\n",
    "            tile_size = (resize, int(img.shape[0] * resize / img.shape[1]))\n",
    "        img = cv2.resize(img, dsize=tile_size, interpolation=cv2.INTER_CUBIC)\n",
    "    else:\n",
    "        tile_size = img.shape\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY);\n",
    "    _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    main_contour = sorted(contours, key=cv2.contourArea, reverse=True)[0]\n",
    "\n",
    "    ff = np.zeros((gray.shape[0], gray.shape[1]), 'uint8')\n",
    "    cv2.drawContours(ff, main_contour, -1, 1, 15)\n",
    "    ff_mask = np.zeros((gray.shape[0] + 2, gray.shape[1] + 2), 'uint8')\n",
    "    cv2.floodFill(ff, ff_mask, (int(gray.shape[1] / 2), int(gray.shape[0] / 2)), 1)\n",
    "\n",
    "    rect = maxRect(ff)\n",
    "    rectangle = [min(rect[0], rect[2]), max(rect[0], rect[2]), min(rect[1], rect[3]), max(rect[1], rect[3])]\n",
    "    img_crop = img[rectangle[0]:rectangle[1], rectangle[2]:rectangle[3]]\n",
    "    cv2.rectangle(ff, (min(rect[1], rect[3]), min(rect[0], rect[2])), (max(rect[1], rect[3]), max(rect[0], rect[2])), 3,\n",
    "                  2)\n",
    "\n",
    "    return [img_crop, rectangle, tile_size]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    #### TRAIN SET\n",
    "\n",
    "    # INPUT_FOLDER = ROOT_FOLDER + '/input/train'\n",
    "    # CROPSET_FOLDER = ROOT_FOLDER + '/input/train_cropped'\n",
    "    #\n",
    "    # total_images = glob.glob(os.path.join(INPUT_FOLDER, FILE_PATTERN))\n",
    "    # total = len(total_images)\n",
    "    #\n",
    "    # for clazz in ClassNames:\n",
    "    #     OUTPUT_FOLDER = os.path.join(CROPSET_FOLDER, clazz)\n",
    "    #     if not os.path.exists(OUTPUT_FOLDER): os.makedirs(OUTPUT_FOLDER)\n",
    "    #\n",
    "    #     total_images = glob.glob(os.path.join(INPUT_FOLDER, clazz, FILE_PATTERN))\n",
    "    #     total = len(total_images)\n",
    "    #     for i, input_filename in enumerate(total_images):\n",
    "    #         img = cv2.imread(input_filename)\n",
    "    #\n",
    "    #         img_crop, rectangle, tile_size = cropCircle(img, resize=None)\n",
    "    #\n",
    "    #         basename = ntpath.basename(input_filename)\n",
    "    #         output_filename = os.path.join(OUTPUT_FOLDER, basename)\n",
    "    #         cv2.imwrite(output_filename, img_crop)\n",
    "    #\n",
    "    #         if i % 20 == 0:\n",
    "    #             print(\"Cropped {}/{} images\".format(i, total))\n",
    "    #\n",
    "\n",
    "    INPUT_FOLDER = ROOT_FOLDER + '/input/test'\n",
    "    CROPSET_FOLDER = ROOT_FOLDER + '/input/test_cropped'\n",
    "\n",
    "    total_images = glob.glob(os.path.join(INPUT_FOLDER, FILE_PATTERN))\n",
    "    total = len(total_images)\n",
    "\n",
    "    OUTPUT_FOLDER = CROPSET_FOLDER\n",
    "    if not os.path.exists(OUTPUT_FOLDER): os.makedirs(OUTPUT_FOLDER)\n",
    "\n",
    "    total_images = glob.glob(os.path.join(INPUT_FOLDER, FILE_PATTERN))\n",
    "    total = len(total_images)\n",
    "    for i, input_filename in enumerate(total_images):\n",
    "        img = cv2.imread(input_filename)\n",
    "\n",
    "        img_crop, rectangle, tile_size = cropCircle(img, resize=None)\n",
    "\n",
    "        basename = ntpath.basename(input_filename)\n",
    "        output_filename = os.path.join(OUTPUT_FOLDER, basename)\n",
    "        cv2.imwrite(output_filename, img_crop)\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            print(\"Cropped {}/{} images\".format(i, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading unet_128x128x3_sp0.8_sh0.78_zm0.4_rt180_vf1_hf1_ws0.3_hs0.3/weights.h5 ...\n",
      "K.image_dim_ordering=tf Channel axis=3\n",
      "Input folder: /Users/keerat/Documents/Research//input/test_resized\n",
      "Processed 50/512 files ...\n",
      "Processed 100/512 files ...\n",
      "Processed 150/512 files ...\n",
      "Processed 200/512 files ...\n",
      "Processed 250/512 files ...\n",
      "Processed 300/512 files ...\n",
      "Processed 350/512 files ...\n",
      "Processed 400/512 files ...\n",
      "Processed 450/512 files ...\n",
      "Processed 500/512 files ...\n",
      "Input folder: /Users/keerat/Documents/Research//input/train_resized/Type_1\n",
      "Processed 50/249 files ...\n",
      "Processed 100/249 files ...\n",
      "Processed 150/249 files ...\n",
      "Processed 200/249 files ...\n",
      "Input folder: /Users/keerat/Documents/Research//input/train_resized/Type_2\n",
      "Processed 50/772 files ...\n",
      "Processed 100/772 files ...\n",
      "Processed 150/772 files ...\n",
      "Processed 200/772 files ...\n",
      "Processed 250/772 files ...\n",
      "Processed 300/772 files ...\n",
      "Processed 350/772 files ...\n",
      "Processed 400/772 files ...\n",
      "Processed 450/772 files ...\n",
      "Processed 500/772 files ...\n",
      "Processed 550/772 files ...\n",
      "Processed 600/772 files ...\n",
      "Processed 650/772 files ...\n",
      "Processed 700/772 files ...\n",
      "Processed 750/772 files ...\n",
      "Input folder: /Users/keerat/Documents/Research//input/train_resized/Type_3\n",
      "Processed 50/445 files ...\n",
      "Processed 100/445 files ...\n",
      "Processed 150/445 files ...\n",
      "Processed 200/445 files ...\n",
      "Processed 250/445 files ...\n",
      "Processed 300/445 files ...\n",
      "Processed 350/445 files ...\n",
      "Processed 400/445 files ...\n"
     ]
    }
   ],
   "source": [
    "import ntpath\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocessing(img):\n",
    "    return img * rescale\n",
    "\n",
    "\n",
    "def inverse_preprocessing(img):\n",
    "    return img / rescale\n",
    "\n",
    "\n",
    "def to_binary_mask(mask, t=0.00001):\n",
    "    mask = inverse_preprocessing(mask)\n",
    "\n",
    "    ### Threshold the RGB image  - This step increase sensitivity\n",
    "    mask[mask > t] = 255\n",
    "    mask[mask <= t] = 0\n",
    "\n",
    "    ### To grayscale and normalize\n",
    "    mask_gray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    mask_gray = cv2.normalize(src=mask_gray, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "\n",
    "    ### Auto binary threshold\n",
    "    (thresh, mask_binary) = cv2.threshold(mask_gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    return mask_binary\n",
    "\n",
    "\n",
    "def find_bbox(mask_binary, margin_factor=None):\n",
    "    ret, thresh = cv2.threshold(mask_binary, 127, 255, 0)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the index of the largest contour\n",
    "    areas = [cv2.contourArea(c) for c in contours]\n",
    "    if len(areas) == 0:\n",
    "        return (0, 0, mask_binary.shape[0], mask_binary.shape[1], False)\n",
    "    else:\n",
    "        max_index = np.argmax(areas)\n",
    "        cnt = contours[max_index]\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "        if margin_factor != None and margin_factor > 0:\n",
    "            wm = w * margin_factor\n",
    "            hm = h * margin_factor\n",
    "            x -= wm\n",
    "            y -= hm\n",
    "            w += 2 * wm\n",
    "            h += 2 * hm\n",
    "            x = max(0, x)\n",
    "            y = max(0, y)\n",
    "            X = min(x + w, mask_binary.shape[1])\n",
    "            Y = min(y + h, mask_binary.shape[0])\n",
    "            w = X - x\n",
    "            h = Y - y\n",
    "        return (int(x), int(y), int(w), int(h), True)\n",
    "\n",
    "\n",
    "def transform_bbox(bbox, from_dim, to_dim):\n",
    "    H0, W0 = from_dim\n",
    "    H1, W1 = to_dim\n",
    "    x, y, w, h = bbox\n",
    "    w_factor = 1. * W1 / W0\n",
    "    h_factor = 1. * H1 / H0\n",
    "    return max(0, int(math.floor(x * w_factor))), \\\n",
    "           max(0, int(math.floor(y * h_factor))), \\\n",
    "           int(math.floor(w * w_factor)), \\\n",
    "           int(math.floor(h * h_factor))\n",
    "\n",
    "\n",
    "def predict_and_crop(model, original_folder, resized_folder, output_folder, margin_factor):\n",
    "    generate_previews = False #Set to True if you want to see the overlay of bbox on original image\n",
    "    generate_crops = True\n",
    "    generate_masks = False\n",
    "\n",
    "    if not os.path.exists(output_folder): os.makedirs(output_folder)\n",
    "\n",
    "    # Test images\n",
    "    print('Input folder: {}'.format(resized_folder))\n",
    "    test_image_files = np.sort(glob.glob(os.path.join(resized_folder, '*.png')))\n",
    "    total = len(test_image_files)\n",
    "    for i, filename in enumerate(test_image_files):\n",
    "        if i > 0 and i % 50 == 0:\n",
    "            print('Processed {}/{} files ...'.format(i, total))\n",
    "\n",
    "        basename = ntpath.basename(filename)\n",
    "        img1 = cv2.resize(cv2.imread(filename), dsize=(img_height, img_width))\n",
    "        img = preprocessing(img1)\n",
    "        img = img[None,]  # Add dimension\n",
    "\n",
    "        predict = model.predict(img, batch_size=1, verbose=0)\n",
    "\n",
    "        # extract binary mask\n",
    "        binary_mask = to_binary_mask(predict[0])\n",
    "        morphed_mask = morphology_clean(binary_mask)\n",
    "        x, y, w, h, success = find_bbox(morphed_mask, margin_factor)\n",
    "\n",
    "        original_img_file = os.path.join(original_folder, basename.replace('.png', '.jpg'))\n",
    "        original = cv2.imread(original_img_file)\n",
    "        if original is None:\n",
    "            raise AssertionError(\"Cannot read the original image:{}\".format(original_img_file))\n",
    "\n",
    "        # transform bbox back to original dimension\n",
    "        x1, y1, w1, h1 = transform_bbox(bbox=(x, y, w, h), from_dim=morphed_mask.shape, to_dim=original.shape[0:2])\n",
    "\n",
    "        if generate_crops:\n",
    "            cropped = original[y1:y1 + h1, x1:x1 + w1, :]\n",
    "            cropped_filename = os.path.join(output_folder, basename.replace('.png', OUTPUT_FILE_EXT))\n",
    "            if cropped.mean() <= 15 or not success: # a black crop or fail to find bounding box\n",
    "                img_crop, rectangle, tile_size = cropCircle(original, resize=None)\n",
    "                cv2.imwrite(cropped_filename, img_crop)\n",
    "            else:\n",
    "                cv2.imwrite(cropped_filename, cropped)\n",
    "\n",
    "        # For debug & preview\n",
    "        if generate_masks:\n",
    "            cv2.imwrite(os.path.join(output_folder, basename.replace('.png', '_mask.png')), morphed_mask)\n",
    "\n",
    "        if generate_previews:\n",
    "            # Highlight the mask in original\n",
    "            img_highlighted = original.copy()\n",
    "            original_mask = cv2.resize(morphed_mask, dsize=(original.shape[1], original.shape[0]),\n",
    "                                       interpolation=cv2.INTER_NEAREST)\n",
    "            blue_channel = img_highlighted[:, :, 0]\n",
    "            blue_channel[original_mask > 0] = 255\n",
    "            cv2.rectangle(img_highlighted, (x1, y1), (x1 + w1, y1 + h1), (0, 255, 0), 3)\n",
    "            preview_filename = os.path.join(output_folder, basename.replace('.png', '_preview.jpg'))\n",
    "            cv2.imwrite(preview_filename, img_highlighted)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    weight_file = os.path.join(info, 'weights.h5')\n",
    "    model = load_model(img_height, img_width, nb_channels, learning_rate, weight_file)\n",
    "\n",
    "    # predict the ROI of test images\n",
    "    predict_and_crop(model, TESTSET_INPUT_FOLDER, TESTSET_RESIZED_FOLDER, TESTSET_OUTPUT_FOLDER, margin)\n",
    "\n",
    "    # predict the ROI of train images\n",
    "    for c in ClassNames:\n",
    "        ORIGINAL_FOLDER = os.path.join(TRAINSET_INPUT_FOLDER, c)\n",
    "        INPUT_FOLDER = os.path.join(TRAINSET_RESIZED_FOLDER, c)\n",
    "        OUTPUT_FOLDER = os.path.join(TRAINSET_OUTPUT_FOLDER, c)\n",
    "        predict_and_crop(model, ORIGINAL_FOLDER, INPUT_FOLDER, OUTPUT_FOLDER, margin)\n",
    "\n",
    "    if os.path.exists(ADDSET_INPUT_FOLDER):\n",
    "        # predict the ROI of additional images\n",
    "        for c in ClassNames:\n",
    "            ORIGINAL_FOLDER = os.path.join(ADDSET_INPUT_FOLDER, c)\n",
    "            INPUT_FOLDER = os.path.join(ADDSET_RESIZED_FOLDER, c)\n",
    "            OUTPUT_FOLDER = os.path.join(ADDSET_OUTPUT_FOLDER, c)\n",
    "            predict_and_crop(model, ORIGINAL_FOLDER, INPUT_FOLDER, OUTPUT_FOLDER, margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
